{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08ac2305",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # data frame library\n",
    "import seaborn as sns # data visialization library\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2aa1befc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('uci breast cancer dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7a7c053",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   ...  radius_worst  texture_worst  perimeter_worst  area_worst  \\\n",
       "0  ...         25.38          17.33           184.60      2019.0   \n",
       "1  ...         24.99          23.41           158.80      1956.0   \n",
       "2  ...         23.57          25.53           152.50      1709.0   \n",
       "3  ...         14.91          26.50            98.87       567.7   \n",
       "4  ...         22.54          16.67           152.20      1575.0   \n",
       "\n",
       "   smoothness_worst  compactness_worst  concavity_worst  concave points_worst  \\\n",
       "0            0.1622             0.6656           0.7119                0.2654   \n",
       "1            0.1238             0.1866           0.2416                0.1860   \n",
       "2            0.1444             0.4245           0.4504                0.2430   \n",
       "3            0.2098             0.8663           0.6869                0.2575   \n",
       "4            0.1374             0.2050           0.4000                0.1625   \n",
       "\n",
       "   symmetry_worst  fractal_dimension_worst  \n",
       "0          0.4601                  0.11890  \n",
       "1          0.2750                  0.08902  \n",
       "2          0.3613                  0.08758  \n",
       "3          0.6638                  0.17300  \n",
       "4          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af0942e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 32 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   id                       569 non-null    int64  \n",
      " 1   diagnosis                569 non-null    object \n",
      " 2   radius_mean              569 non-null    float64\n",
      " 3   texture_mean             569 non-null    float64\n",
      " 4   perimeter_mean           569 non-null    float64\n",
      " 5   area_mean                569 non-null    float64\n",
      " 6   smoothness_mean          569 non-null    float64\n",
      " 7   compactness_mean         569 non-null    float64\n",
      " 8   concavity_mean           569 non-null    float64\n",
      " 9   concave points_mean      569 non-null    float64\n",
      " 10  symmetry_mean            569 non-null    float64\n",
      " 11  fractal_dimension_mean   569 non-null    float64\n",
      " 12  radius_se                569 non-null    float64\n",
      " 13  texture_se               569 non-null    float64\n",
      " 14  perimeter_se             569 non-null    float64\n",
      " 15  area_se                  569 non-null    float64\n",
      " 16  smoothness_se            569 non-null    float64\n",
      " 17  compactness_se           569 non-null    float64\n",
      " 18  concavity_se             569 non-null    float64\n",
      " 19  concave points_se        569 non-null    float64\n",
      " 20  symmetry_se              569 non-null    float64\n",
      " 21  fractal_dimension_se     569 non-null    float64\n",
      " 22  radius_worst             569 non-null    float64\n",
      " 23  texture_worst            569 non-null    float64\n",
      " 24  perimeter_worst          569 non-null    float64\n",
      " 25  area_worst               569 non-null    float64\n",
      " 26  smoothness_worst         569 non-null    float64\n",
      " 27  compactness_worst        569 non-null    float64\n",
      " 28  concavity_worst          569 non-null    float64\n",
      " 29  concave points_worst     569 non-null    float64\n",
      " 30  symmetry_worst           569 non-null    float64\n",
      " 31  fractal_dimension_worst  569 non-null    float64\n",
      "dtypes: float64(30), int64(1), object(1)\n",
      "memory usage: 142.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f57d46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['id'], axis = 'columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0bcfadaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='diagnosis', ylabel='count'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x='diagnosis',data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "acc1538e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "B    357\n",
       "M    212\n",
       "Name: diagnosis, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.diagnosis.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a9ee750",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop('diagnosis',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "78ac2285",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[['diagnosis']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "18243178",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4c2e24bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain, xtest, ytrain, ytest = train_test_split(x,y,train_size=.75, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8ed3b2",
   "metadata": {},
   "source": [
    "# Apply Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "23f7078f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f9e1505e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c69fafe1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.fit(xtrain,ytrain) #train the model with 70% of data from dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a23fae79",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = dt.predict(xtest) # pred is corrsponding to ytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b0e4ae93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>540</th>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>143 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    diagnosis\n",
       "204         B\n",
       "70          M\n",
       "131         M\n",
       "431         B\n",
       "540         B\n",
       "..        ...\n",
       "89          B\n",
       "199         M\n",
       "411         B\n",
       "18          M\n",
       "390         B\n",
       "\n",
       "[143 rows x 1 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6bf432e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['B', 'M', 'M', 'B', 'B', 'M', 'M', 'M', 'B', 'M', 'B', 'M', 'B',\n",
       "       'M', 'B', 'M', 'B', 'B', 'B', 'M', 'B', 'B', 'M', 'B', 'B', 'B',\n",
       "       'B', 'B', 'B', 'M', 'B', 'B', 'B', 'B', 'B', 'B', 'M', 'B', 'M',\n",
       "       'B', 'B', 'M', 'B', 'B', 'B', 'B', 'M', 'B', 'B', 'B', 'M', 'M',\n",
       "       'B', 'B', 'B', 'B', 'B', 'M', 'M', 'B', 'B', 'M', 'M', 'B', 'B',\n",
       "       'B', 'M', 'M', 'B', 'B', 'M', 'M', 'B', 'M', 'B', 'B', 'B', 'M',\n",
       "       'B', 'B', 'M', 'B', 'B', 'M', 'M', 'M', 'M', 'M', 'B', 'B', 'B',\n",
       "       'B', 'M', 'B', 'B', 'B', 'M', 'M', 'B', 'M', 'M', 'B', 'M', 'M',\n",
       "       'B', 'B', 'B', 'M', 'B', 'B', 'M', 'B', 'B', 'M', 'B', 'M', 'B',\n",
       "       'B', 'B', 'M', 'M', 'B', 'B', 'M', 'B', 'M', 'M', 'B', 'B', 'M',\n",
       "       'M', 'M', 'M', 'B', 'B', 'M', 'M', 'B', 'B', 'M', 'B', 'M', 'B'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred # Predicted value of Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d5339ba1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9440559440559441"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.score(xtest,ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ceeca44",
   "metadata": {},
   "source": [
    "# Evaluate the ML model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cc1a2a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report , accuracy_score, confusion_matrix, plot_roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4db31bba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           B       0.98      0.93      0.95        89\n",
      "           M       0.90      0.96      0.93        54\n",
      "\n",
      "    accuracy                           0.94       143\n",
      "   macro avg       0.94      0.95      0.94       143\n",
      "weighted avg       0.95      0.94      0.94       143\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(ytest,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "075426b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_confusion_matrix = confusion_matrix(ytest,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1cd72ff0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(test_confusion_matrix, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "240d74aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "tp, fp, fn, tn = confusion_matrix(ytest,pred).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1626d66c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9440559440559441"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.score(xtest,ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4125e5",
   "metadata": {},
   "source": [
    "# Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b62f3dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "92f20e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier() # default parameters, 100 Tree = n_estimators=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9415bea3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8dd2bcab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.972027972027972"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(xtest, ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2df08b3",
   "metadata": {},
   "source": [
    "# Some dataset for practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "eae045e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://scikit-learn.org/stable/datasets/toy_dataset.html\n",
    "#https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_iris.html\n",
    "#https://scikit-learn.org/stable/datasets/real_world.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813ef59a",
   "metadata": {},
   "source": [
    "# Hyper Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "420ee1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\n",
    "#https://scikit-learn.org/0.16/modules/generated/sklearn.grid_search.RandomizedSearchCV.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa2f29b",
   "metadata": {},
   "source": [
    "# Grid Search CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dc409ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "trees = np.random.randint(15,150,30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e1a12aa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([149, 119, 131,  71, 126,  53,  35,  23,  15, 137,  38,  23,  33,\n",
       "        73,  65, 100,  78,  22,  95, 113, 135,  45,  20,  96, 123,  32,\n",
       "       144, 106, 113,  85])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "aa7d9d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid={\n",
    "    'n_estimators': [200, 500],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'max_depth' : [4,5,6,7,8],\n",
    "    'criterion' :['gini', 'entropy']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "136bc7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "67f17146",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_grid=GridSearchCV(estimator=clf,param_grid=param_grid,cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0f645847",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, estimator=RandomForestClassifier(),\n",
       "             param_grid={'criterion': ['gini', 'entropy'],\n",
       "                         'max_depth': [4, 5, 6, 7, 8],\n",
       "                         'max_features': ['auto', 'sqrt', 'log2'],\n",
       "                         'n_estimators': [200, 500]})"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_grid.fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "42a9a9a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.22619907, 0.69733453, 0.27759091, 0.61928678, 0.27891898,\n",
       "        0.55718788, 0.21508749, 0.71109684, 0.21543797, 0.5601662 ,\n",
       "        0.20210552, 0.5023303 , 0.22406705, 0.56214778, 0.23237475,\n",
       "        0.52459828, 0.19646764, 0.50165613, 0.20711501, 0.54886627,\n",
       "        0.21342953, 0.61933271, 0.20346141, 0.50829323, 0.22970613,\n",
       "        0.5581789 , 0.21575809, 0.57644375, 0.23270694, 0.56350104,\n",
       "        0.24336346, 0.56416702, 0.22471452, 0.6439333 , 0.21876446,\n",
       "        0.53890363, 0.22708074, 0.56747452, 0.22639998, 0.55953439,\n",
       "        0.2141002 , 0.53356377, 0.22439766, 0.55918042, 0.22506452,\n",
       "        0.56182742, 0.21309662, 0.53058847, 0.22606881, 0.56183791,\n",
       "        0.23639305, 0.6326437 , 0.22407381, 0.56380868, 0.23402667,\n",
       "        0.56449397, 0.22573709, 0.56050475, 0.21442294, 0.53422769]),\n",
       " 'std_fit_time': array([0.02610997, 0.06746962, 0.00995171, 0.10367136, 0.02311623,\n",
       "        0.04283498, 0.00739042, 0.02053632, 0.01292975, 0.04199045,\n",
       "        0.00308759, 0.00125129, 0.00658244, 0.02381342, 0.02972977,\n",
       "        0.00986016, 0.00292638, 0.00783659, 0.00188318, 0.04706472,\n",
       "        0.004958  , 0.05712714, 0.00295435, 0.01930371, 0.01832748,\n",
       "        0.01303427, 0.00694518, 0.02541185, 0.02433345, 0.05225305,\n",
       "        0.01068017, 0.00653044, 0.00168404, 0.06892108, 0.00611962,\n",
       "        0.00818599, 0.00589092, 0.0080237 , 0.00214734, 0.00427908,\n",
       "        0.00260551, 0.00294387, 0.00292036, 0.00418352, 0.0026015 ,\n",
       "        0.00612985, 0.00169534, 0.00353945, 0.00123623, 0.00463762,\n",
       "        0.00533846, 0.01384987, 0.00898858, 0.00419479, 0.00774   ,\n",
       "        0.01279851, 0.00285921, 0.00533821, 0.00245365, 0.0033078 ]),\n",
       " 'mean_score_time': array([0.01707403, 0.04521227, 0.02062154, 0.04564691, 0.01695657,\n",
       "        0.03888432, 0.01596808, 0.05517928, 0.01528716, 0.03823344,\n",
       "        0.01630123, 0.03789131, 0.01696197, 0.04321194, 0.01562945,\n",
       "        0.03689814, 0.01563406, 0.03656872, 0.01529082, 0.03623549,\n",
       "        0.01695609, 0.04120692, 0.01562651, 0.0369192 , 0.01662294,\n",
       "        0.03755919, 0.01662477, 0.0389084 , 0.01628455, 0.03857382,\n",
       "        0.01628248, 0.03656324, 0.01530838, 0.04787183, 0.01561594,\n",
       "        0.03855387, 0.01527818, 0.03657349, 0.01528883, 0.03559486,\n",
       "        0.01594766, 0.03592038, 0.0149525 , 0.03656689, 0.01561793,\n",
       "        0.03657238, 0.01496005, 0.03623621, 0.01527476, 0.03656157,\n",
       "        0.01659695, 0.03822478, 0.01629297, 0.05619693, 0.01563191,\n",
       "        0.03590735, 0.01528486, 0.03589702, 0.01563207, 0.03624884]),\n",
       " 'std_score_time': array([2.03274909e-03, 4.48476355e-03, 5.88597617e-03, 1.30452956e-02,\n",
       "        2.03239311e-06, 1.60790537e-03, 1.60184641e-05, 2.23410796e-02,\n",
       "        4.73537472e-04, 9.37626935e-04, 9.33617492e-04, 1.61169519e-03,\n",
       "        8.37906628e-04, 4.90257262e-03, 4.54484697e-04, 1.40719901e-03,\n",
       "        9.38059366e-04, 9.40482097e-04, 4.71494359e-04, 4.71597708e-04,\n",
       "        1.40939406e-03, 4.98575765e-03, 4.77963957e-04, 1.27657262e-05,\n",
       "        1.25501036e-03, 1.24387553e-03, 9.38981083e-04, 2.81177903e-03,\n",
       "        4.93317187e-04, 9.52326385e-04, 4.76070118e-04, 4.66494056e-04,\n",
       "        4.73860510e-04, 1.27959960e-02, 4.68428986e-04, 1.25724752e-03,\n",
       "        4.65158918e-04, 4.72797381e-04, 4.80724267e-04, 4.71152367e-04,\n",
       "        1.30388784e-05, 1.22052306e-05, 1.03400268e-05, 4.53743456e-04,\n",
       "        4.65434443e-04, 4.88183814e-04, 0.00000000e+00, 4.70246478e-04,\n",
       "        4.61679136e-04, 4.80193341e-04, 9.41281630e-04, 2.03987422e-03,\n",
       "        4.68101971e-04, 2.58755765e-02, 4.56145568e-04, 1.38109105e-05,\n",
       "        4.74935289e-04, 1.87973054e-05, 4.75113070e-04, 4.62675291e-04]),\n",
       " 'param_criterion': masked_array(data=['gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_max_depth': masked_array(data=[4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6,\n",
       "                    7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 4, 4, 4, 4, 4, 4,\n",
       "                    5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7,\n",
       "                    8, 8, 8, 8, 8, 8],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_max_features': masked_array(data=['auto', 'auto', 'sqrt', 'sqrt', 'log2', 'log2', 'auto',\n",
       "                    'auto', 'sqrt', 'sqrt', 'log2', 'log2', 'auto', 'auto',\n",
       "                    'sqrt', 'sqrt', 'log2', 'log2', 'auto', 'auto', 'sqrt',\n",
       "                    'sqrt', 'log2', 'log2', 'auto', 'auto', 'sqrt', 'sqrt',\n",
       "                    'log2', 'log2', 'auto', 'auto', 'sqrt', 'sqrt', 'log2',\n",
       "                    'log2', 'auto', 'auto', 'sqrt', 'sqrt', 'log2', 'log2',\n",
       "                    'auto', 'auto', 'sqrt', 'sqrt', 'log2', 'log2', 'auto',\n",
       "                    'auto', 'sqrt', 'sqrt', 'log2', 'log2', 'auto', 'auto',\n",
       "                    'sqrt', 'sqrt', 'log2', 'log2'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_n_estimators': masked_array(data=[200, 500, 200, 500, 200, 500, 200, 500, 200, 500, 200,\n",
       "                    500, 200, 500, 200, 500, 200, 500, 200, 500, 200, 500,\n",
       "                    200, 500, 200, 500, 200, 500, 200, 500, 200, 500, 200,\n",
       "                    500, 200, 500, 200, 500, 200, 500, 200, 500, 200, 500,\n",
       "                    200, 500, 200, 500, 200, 500, 200, 500, 200, 500, 200,\n",
       "                    500, 200, 500, 200, 500],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'auto',\n",
       "   'n_estimators': 200},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'auto',\n",
       "   'n_estimators': 500},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'sqrt',\n",
       "   'n_estimators': 200},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'sqrt',\n",
       "   'n_estimators': 500},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'log2',\n",
       "   'n_estimators': 200},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'log2',\n",
       "   'n_estimators': 500},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'auto',\n",
       "   'n_estimators': 200},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'auto',\n",
       "   'n_estimators': 500},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'sqrt',\n",
       "   'n_estimators': 200},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'sqrt',\n",
       "   'n_estimators': 500},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'log2',\n",
       "   'n_estimators': 200},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'log2',\n",
       "   'n_estimators': 500},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 'auto',\n",
       "   'n_estimators': 200},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 'auto',\n",
       "   'n_estimators': 500},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 'sqrt',\n",
       "   'n_estimators': 200},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 'sqrt',\n",
       "   'n_estimators': 500},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 'log2',\n",
       "   'n_estimators': 200},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 'log2',\n",
       "   'n_estimators': 500},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'max_features': 'auto',\n",
       "   'n_estimators': 200},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'max_features': 'auto',\n",
       "   'n_estimators': 500},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'max_features': 'sqrt',\n",
       "   'n_estimators': 200},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'max_features': 'sqrt',\n",
       "   'n_estimators': 500},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'max_features': 'log2',\n",
       "   'n_estimators': 200},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'max_features': 'log2',\n",
       "   'n_estimators': 500},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'max_features': 'auto',\n",
       "   'n_estimators': 200},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'max_features': 'auto',\n",
       "   'n_estimators': 500},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'max_features': 'sqrt',\n",
       "   'n_estimators': 200},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'max_features': 'sqrt',\n",
       "   'n_estimators': 500},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'max_features': 'log2',\n",
       "   'n_estimators': 200},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'max_features': 'log2',\n",
       "   'n_estimators': 500},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'auto',\n",
       "   'n_estimators': 200},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'auto',\n",
       "   'n_estimators': 500},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'sqrt',\n",
       "   'n_estimators': 200},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'sqrt',\n",
       "   'n_estimators': 500},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'log2',\n",
       "   'n_estimators': 200},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 4,\n",
       "   'max_features': 'log2',\n",
       "   'n_estimators': 500},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'auto',\n",
       "   'n_estimators': 200},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'auto',\n",
       "   'n_estimators': 500},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'sqrt',\n",
       "   'n_estimators': 200},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'sqrt',\n",
       "   'n_estimators': 500},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'log2',\n",
       "   'n_estimators': 200},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'log2',\n",
       "   'n_estimators': 500},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 'auto',\n",
       "   'n_estimators': 200},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 'auto',\n",
       "   'n_estimators': 500},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 'sqrt',\n",
       "   'n_estimators': 200},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 'sqrt',\n",
       "   'n_estimators': 500},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 'log2',\n",
       "   'n_estimators': 200},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 'log2',\n",
       "   'n_estimators': 500},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 7,\n",
       "   'max_features': 'auto',\n",
       "   'n_estimators': 200},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 7,\n",
       "   'max_features': 'auto',\n",
       "   'n_estimators': 500},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 7,\n",
       "   'max_features': 'sqrt',\n",
       "   'n_estimators': 200},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 7,\n",
       "   'max_features': 'sqrt',\n",
       "   'n_estimators': 500},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 7,\n",
       "   'max_features': 'log2',\n",
       "   'n_estimators': 200},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 7,\n",
       "   'max_features': 'log2',\n",
       "   'n_estimators': 500},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 8,\n",
       "   'max_features': 'auto',\n",
       "   'n_estimators': 200},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 8,\n",
       "   'max_features': 'auto',\n",
       "   'n_estimators': 500},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 8,\n",
       "   'max_features': 'sqrt',\n",
       "   'n_estimators': 200},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 8,\n",
       "   'max_features': 'sqrt',\n",
       "   'n_estimators': 500},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 8,\n",
       "   'max_features': 'log2',\n",
       "   'n_estimators': 200},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 8,\n",
       "   'max_features': 'log2',\n",
       "   'n_estimators': 500}],\n",
       " 'split0_test_score': array([0.94366197, 0.93661972, 0.93661972, 0.93661972, 0.93661972,\n",
       "        0.93661972, 0.95774648, 0.93661972, 0.94366197, 0.93661972,\n",
       "        0.93661972, 0.93661972, 0.94366197, 0.94366197, 0.94366197,\n",
       "        0.93661972, 0.94366197, 0.94366197, 0.95070423, 0.93661972,\n",
       "        0.93661972, 0.92957746, 0.94366197, 0.93661972, 0.93661972,\n",
       "        0.94366197, 0.94366197, 0.93661972, 0.94366197, 0.94366197,\n",
       "        0.92957746, 0.92957746, 0.94366197, 0.92957746, 0.92957746,\n",
       "        0.92957746, 0.93661972, 0.94366197, 0.94366197, 0.95070423,\n",
       "        0.95070423, 0.92957746, 0.95070423, 0.93661972, 0.95070423,\n",
       "        0.95070423, 0.95070423, 0.94366197, 0.94366197, 0.94366197,\n",
       "        0.96478873, 0.95070423, 0.94366197, 0.95070423, 0.95070423,\n",
       "        0.95070423, 0.93661972, 0.94366197, 0.94366197, 0.95774648]),\n",
       " 'split1_test_score': array([0.95774648, 0.95774648, 0.95774648, 0.95774648, 0.95774648,\n",
       "        0.95774648, 0.96478873, 0.95774648, 0.95070423, 0.95774648,\n",
       "        0.95070423, 0.96478873, 0.96478873, 0.95774648, 0.96478873,\n",
       "        0.95774648, 0.96478873, 0.95774648, 0.95070423, 0.96478873,\n",
       "        0.95774648, 0.95774648, 0.96478873, 0.95774648, 0.95774648,\n",
       "        0.96478873, 0.95774648, 0.95774648, 0.96478873, 0.96478873,\n",
       "        0.95774648, 0.96478873, 0.96478873, 0.95774648, 0.96478873,\n",
       "        0.95774648, 0.95774648, 0.95774648, 0.95774648, 0.95774648,\n",
       "        0.95774648, 0.96478873, 0.95774648, 0.95774648, 0.95774648,\n",
       "        0.96478873, 0.96478873, 0.96478873, 0.96478873, 0.95774648,\n",
       "        0.95774648, 0.95774648, 0.96478873, 0.96478873, 0.96478873,\n",
       "        0.95774648, 0.95774648, 0.96478873, 0.95774648, 0.96478873]),\n",
       " 'split2_test_score': array([0.95774648, 0.94366197, 0.95070423, 0.95070423, 0.95774648,\n",
       "        0.94366197, 0.95070423, 0.95070423, 0.95774648, 0.95070423,\n",
       "        0.95774648, 0.95070423, 0.94366197, 0.95070423, 0.94366197,\n",
       "        0.94366197, 0.95070423, 0.94366197, 0.94366197, 0.95070423,\n",
       "        0.93661972, 0.95070423, 0.95070423, 0.95070423, 0.95774648,\n",
       "        0.94366197, 0.95774648, 0.95070423, 0.95774648, 0.95070423,\n",
       "        0.95774648, 0.96478873, 0.93661972, 0.95774648, 0.96478873,\n",
       "        0.95070423, 0.94366197, 0.95774648, 0.93661972, 0.96478873,\n",
       "        0.95774648, 0.95774648, 0.95070423, 0.95774648, 0.97183099,\n",
       "        0.96478873, 0.95070423, 0.95774648, 0.95774648, 0.95774648,\n",
       "        0.96478873, 0.95070423, 0.95070423, 0.95774648, 0.93661972,\n",
       "        0.95774648, 0.95774648, 0.95774648, 0.95774648, 0.96478873]),\n",
       " 'mean_test_score': array([0.95305164, 0.94600939, 0.94835681, 0.94835681, 0.95070423,\n",
       "        0.94600939, 0.95774648, 0.94835681, 0.95070423, 0.94835681,\n",
       "        0.94835681, 0.95070423, 0.95070423, 0.95070423, 0.95070423,\n",
       "        0.94600939, 0.95305164, 0.94835681, 0.94835681, 0.95070423,\n",
       "        0.94366197, 0.94600939, 0.95305164, 0.94835681, 0.95070423,\n",
       "        0.95070423, 0.95305164, 0.94835681, 0.95539906, 0.95305164,\n",
       "        0.94835681, 0.95305164, 0.94835681, 0.94835681, 0.95305164,\n",
       "        0.94600939, 0.94600939, 0.95305164, 0.94600939, 0.95774648,\n",
       "        0.95539906, 0.95070423, 0.95305164, 0.95070423, 0.9600939 ,\n",
       "        0.9600939 , 0.95539906, 0.95539906, 0.95539906, 0.95305164,\n",
       "        0.96244131, 0.95305164, 0.95305164, 0.95774648, 0.95070423,\n",
       "        0.95539906, 0.95070423, 0.95539906, 0.95305164, 0.96244131]),\n",
       " 'std_test_score': array([0.0066395 , 0.00878323, 0.00878323, 0.00878323, 0.00995925,\n",
       "        0.00878323, 0.00574998, 0.00878323, 0.00574998, 0.00878323,\n",
       "        0.00878323, 0.01149995, 0.00995925, 0.00574998, 0.00995925,\n",
       "        0.00878323, 0.00878323, 0.0066395 , 0.00331975, 0.01149995,\n",
       "        0.00995925, 0.01196953, 0.00878323, 0.00878323, 0.00995925,\n",
       "        0.00995925, 0.0066395 , 0.00878323, 0.00878323, 0.00878323,\n",
       "        0.013279  , 0.01659875, 0.01196953, 0.013279  , 0.01659875,\n",
       "        0.01196953, 0.00878323, 0.0066395 , 0.00878323, 0.00574998,\n",
       "        0.00331975, 0.01521301, 0.00331975, 0.00995925, 0.00878323,\n",
       "        0.0066395 , 0.0066395 , 0.00878323, 0.00878323, 0.0066395 ,\n",
       "        0.00331975, 0.00331975, 0.00878323, 0.00574998, 0.01149995,\n",
       "        0.00331975, 0.00995925, 0.00878323, 0.0066395 , 0.00331975]),\n",
       " 'rank_test_score': array([17, 53, 41, 41, 28, 53,  6, 41, 28, 41, 41, 28, 28, 28, 28, 53, 17,\n",
       "        41, 41, 28, 60, 53, 17, 41, 28, 28, 17, 41,  8, 17, 41, 15, 41, 41,\n",
       "        15, 53, 53, 17, 53,  6,  8, 28, 17, 28,  3,  3,  8,  8,  8, 17,  1,\n",
       "        17, 17,  5, 28,  8, 28,  8, 17,  1])}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_grid.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f82c4af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuning_result=pd.DataFrame(clf_grid.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ca437834",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_criterion</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.226199</td>\n",
       "      <td>0.026110</td>\n",
       "      <td>0.017074</td>\n",
       "      <td>0.002033</td>\n",
       "      <td>gini</td>\n",
       "      <td>4</td>\n",
       "      <td>auto</td>\n",
       "      <td>200</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 4, 'max_fea...</td>\n",
       "      <td>0.943662</td>\n",
       "      <td>0.957746</td>\n",
       "      <td>0.957746</td>\n",
       "      <td>0.953052</td>\n",
       "      <td>0.006640</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.697335</td>\n",
       "      <td>0.067470</td>\n",
       "      <td>0.045212</td>\n",
       "      <td>0.004485</td>\n",
       "      <td>gini</td>\n",
       "      <td>4</td>\n",
       "      <td>auto</td>\n",
       "      <td>500</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 4, 'max_fea...</td>\n",
       "      <td>0.936620</td>\n",
       "      <td>0.957746</td>\n",
       "      <td>0.943662</td>\n",
       "      <td>0.946009</td>\n",
       "      <td>0.008783</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.277591</td>\n",
       "      <td>0.009952</td>\n",
       "      <td>0.020622</td>\n",
       "      <td>0.005886</td>\n",
       "      <td>gini</td>\n",
       "      <td>4</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>200</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 4, 'max_fea...</td>\n",
       "      <td>0.936620</td>\n",
       "      <td>0.957746</td>\n",
       "      <td>0.950704</td>\n",
       "      <td>0.948357</td>\n",
       "      <td>0.008783</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.619287</td>\n",
       "      <td>0.103671</td>\n",
       "      <td>0.045647</td>\n",
       "      <td>0.013045</td>\n",
       "      <td>gini</td>\n",
       "      <td>4</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>500</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 4, 'max_fea...</td>\n",
       "      <td>0.936620</td>\n",
       "      <td>0.957746</td>\n",
       "      <td>0.950704</td>\n",
       "      <td>0.948357</td>\n",
       "      <td>0.008783</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.278919</td>\n",
       "      <td>0.023116</td>\n",
       "      <td>0.016957</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>gini</td>\n",
       "      <td>4</td>\n",
       "      <td>log2</td>\n",
       "      <td>200</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 4, 'max_fea...</td>\n",
       "      <td>0.936620</td>\n",
       "      <td>0.957746</td>\n",
       "      <td>0.957746</td>\n",
       "      <td>0.950704</td>\n",
       "      <td>0.009959</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.557188</td>\n",
       "      <td>0.042835</td>\n",
       "      <td>0.038884</td>\n",
       "      <td>0.001608</td>\n",
       "      <td>gini</td>\n",
       "      <td>4</td>\n",
       "      <td>log2</td>\n",
       "      <td>500</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 4, 'max_fea...</td>\n",
       "      <td>0.936620</td>\n",
       "      <td>0.957746</td>\n",
       "      <td>0.943662</td>\n",
       "      <td>0.946009</td>\n",
       "      <td>0.008783</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.215087</td>\n",
       "      <td>0.007390</td>\n",
       "      <td>0.015968</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>gini</td>\n",
       "      <td>5</td>\n",
       "      <td>auto</td>\n",
       "      <td>200</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 5, 'max_fea...</td>\n",
       "      <td>0.957746</td>\n",
       "      <td>0.964789</td>\n",
       "      <td>0.950704</td>\n",
       "      <td>0.957746</td>\n",
       "      <td>0.005750</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.711097</td>\n",
       "      <td>0.020536</td>\n",
       "      <td>0.055179</td>\n",
       "      <td>0.022341</td>\n",
       "      <td>gini</td>\n",
       "      <td>5</td>\n",
       "      <td>auto</td>\n",
       "      <td>500</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 5, 'max_fea...</td>\n",
       "      <td>0.936620</td>\n",
       "      <td>0.957746</td>\n",
       "      <td>0.950704</td>\n",
       "      <td>0.948357</td>\n",
       "      <td>0.008783</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.215438</td>\n",
       "      <td>0.012930</td>\n",
       "      <td>0.015287</td>\n",
       "      <td>0.000474</td>\n",
       "      <td>gini</td>\n",
       "      <td>5</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>200</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 5, 'max_fea...</td>\n",
       "      <td>0.943662</td>\n",
       "      <td>0.950704</td>\n",
       "      <td>0.957746</td>\n",
       "      <td>0.950704</td>\n",
       "      <td>0.005750</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.560166</td>\n",
       "      <td>0.041990</td>\n",
       "      <td>0.038233</td>\n",
       "      <td>0.000938</td>\n",
       "      <td>gini</td>\n",
       "      <td>5</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>500</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 5, 'max_fea...</td>\n",
       "      <td>0.936620</td>\n",
       "      <td>0.957746</td>\n",
       "      <td>0.950704</td>\n",
       "      <td>0.948357</td>\n",
       "      <td>0.008783</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.202106</td>\n",
       "      <td>0.003088</td>\n",
       "      <td>0.016301</td>\n",
       "      <td>0.000934</td>\n",
       "      <td>gini</td>\n",
       "      <td>5</td>\n",
       "      <td>log2</td>\n",
       "      <td>200</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 5, 'max_fea...</td>\n",
       "      <td>0.936620</td>\n",
       "      <td>0.950704</td>\n",
       "      <td>0.957746</td>\n",
       "      <td>0.948357</td>\n",
       "      <td>0.008783</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.502330</td>\n",
       "      <td>0.001251</td>\n",
       "      <td>0.037891</td>\n",
       "      <td>0.001612</td>\n",
       "      <td>gini</td>\n",
       "      <td>5</td>\n",
       "      <td>log2</td>\n",
       "      <td>500</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 5, 'max_fea...</td>\n",
       "      <td>0.936620</td>\n",
       "      <td>0.964789</td>\n",
       "      <td>0.950704</td>\n",
       "      <td>0.950704</td>\n",
       "      <td>0.011500</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.224067</td>\n",
       "      <td>0.006582</td>\n",
       "      <td>0.016962</td>\n",
       "      <td>0.000838</td>\n",
       "      <td>gini</td>\n",
       "      <td>6</td>\n",
       "      <td>auto</td>\n",
       "      <td>200</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 6, 'max_fea...</td>\n",
       "      <td>0.943662</td>\n",
       "      <td>0.964789</td>\n",
       "      <td>0.943662</td>\n",
       "      <td>0.950704</td>\n",
       "      <td>0.009959</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.562148</td>\n",
       "      <td>0.023813</td>\n",
       "      <td>0.043212</td>\n",
       "      <td>0.004903</td>\n",
       "      <td>gini</td>\n",
       "      <td>6</td>\n",
       "      <td>auto</td>\n",
       "      <td>500</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 6, 'max_fea...</td>\n",
       "      <td>0.943662</td>\n",
       "      <td>0.957746</td>\n",
       "      <td>0.950704</td>\n",
       "      <td>0.950704</td>\n",
       "      <td>0.005750</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.232375</td>\n",
       "      <td>0.029730</td>\n",
       "      <td>0.015629</td>\n",
       "      <td>0.000454</td>\n",
       "      <td>gini</td>\n",
       "      <td>6</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>200</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 6, 'max_fea...</td>\n",
       "      <td>0.943662</td>\n",
       "      <td>0.964789</td>\n",
       "      <td>0.943662</td>\n",
       "      <td>0.950704</td>\n",
       "      <td>0.009959</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.524598</td>\n",
       "      <td>0.009860</td>\n",
       "      <td>0.036898</td>\n",
       "      <td>0.001407</td>\n",
       "      <td>gini</td>\n",
       "      <td>6</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>500</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 6, 'max_fea...</td>\n",
       "      <td>0.936620</td>\n",
       "      <td>0.957746</td>\n",
       "      <td>0.943662</td>\n",
       "      <td>0.946009</td>\n",
       "      <td>0.008783</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.196468</td>\n",
       "      <td>0.002926</td>\n",
       "      <td>0.015634</td>\n",
       "      <td>0.000938</td>\n",
       "      <td>gini</td>\n",
       "      <td>6</td>\n",
       "      <td>log2</td>\n",
       "      <td>200</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 6, 'max_fea...</td>\n",
       "      <td>0.943662</td>\n",
       "      <td>0.964789</td>\n",
       "      <td>0.950704</td>\n",
       "      <td>0.953052</td>\n",
       "      <td>0.008783</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.501656</td>\n",
       "      <td>0.007837</td>\n",
       "      <td>0.036569</td>\n",
       "      <td>0.000940</td>\n",
       "      <td>gini</td>\n",
       "      <td>6</td>\n",
       "      <td>log2</td>\n",
       "      <td>500</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 6, 'max_fea...</td>\n",
       "      <td>0.943662</td>\n",
       "      <td>0.957746</td>\n",
       "      <td>0.943662</td>\n",
       "      <td>0.948357</td>\n",
       "      <td>0.006640</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.207115</td>\n",
       "      <td>0.001883</td>\n",
       "      <td>0.015291</td>\n",
       "      <td>0.000471</td>\n",
       "      <td>gini</td>\n",
       "      <td>7</td>\n",
       "      <td>auto</td>\n",
       "      <td>200</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 7, 'max_fea...</td>\n",
       "      <td>0.950704</td>\n",
       "      <td>0.950704</td>\n",
       "      <td>0.943662</td>\n",
       "      <td>0.948357</td>\n",
       "      <td>0.003320</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.548866</td>\n",
       "      <td>0.047065</td>\n",
       "      <td>0.036235</td>\n",
       "      <td>0.000472</td>\n",
       "      <td>gini</td>\n",
       "      <td>7</td>\n",
       "      <td>auto</td>\n",
       "      <td>500</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 7, 'max_fea...</td>\n",
       "      <td>0.936620</td>\n",
       "      <td>0.964789</td>\n",
       "      <td>0.950704</td>\n",
       "      <td>0.950704</td>\n",
       "      <td>0.011500</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.213430</td>\n",
       "      <td>0.004958</td>\n",
       "      <td>0.016956</td>\n",
       "      <td>0.001409</td>\n",
       "      <td>gini</td>\n",
       "      <td>7</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>200</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 7, 'max_fea...</td>\n",
       "      <td>0.936620</td>\n",
       "      <td>0.957746</td>\n",
       "      <td>0.936620</td>\n",
       "      <td>0.943662</td>\n",
       "      <td>0.009959</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.619333</td>\n",
       "      <td>0.057127</td>\n",
       "      <td>0.041207</td>\n",
       "      <td>0.004986</td>\n",
       "      <td>gini</td>\n",
       "      <td>7</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>500</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 7, 'max_fea...</td>\n",
       "      <td>0.929577</td>\n",
       "      <td>0.957746</td>\n",
       "      <td>0.950704</td>\n",
       "      <td>0.946009</td>\n",
       "      <td>0.011970</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.203461</td>\n",
       "      <td>0.002954</td>\n",
       "      <td>0.015627</td>\n",
       "      <td>0.000478</td>\n",
       "      <td>gini</td>\n",
       "      <td>7</td>\n",
       "      <td>log2</td>\n",
       "      <td>200</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 7, 'max_fea...</td>\n",
       "      <td>0.943662</td>\n",
       "      <td>0.964789</td>\n",
       "      <td>0.950704</td>\n",
       "      <td>0.953052</td>\n",
       "      <td>0.008783</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.508293</td>\n",
       "      <td>0.019304</td>\n",
       "      <td>0.036919</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>gini</td>\n",
       "      <td>7</td>\n",
       "      <td>log2</td>\n",
       "      <td>500</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 7, 'max_fea...</td>\n",
       "      <td>0.936620</td>\n",
       "      <td>0.957746</td>\n",
       "      <td>0.950704</td>\n",
       "      <td>0.948357</td>\n",
       "      <td>0.008783</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.229706</td>\n",
       "      <td>0.018327</td>\n",
       "      <td>0.016623</td>\n",
       "      <td>0.001255</td>\n",
       "      <td>gini</td>\n",
       "      <td>8</td>\n",
       "      <td>auto</td>\n",
       "      <td>200</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 8, 'max_fea...</td>\n",
       "      <td>0.936620</td>\n",
       "      <td>0.957746</td>\n",
       "      <td>0.957746</td>\n",
       "      <td>0.950704</td>\n",
       "      <td>0.009959</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.558179</td>\n",
       "      <td>0.013034</td>\n",
       "      <td>0.037559</td>\n",
       "      <td>0.001244</td>\n",
       "      <td>gini</td>\n",
       "      <td>8</td>\n",
       "      <td>auto</td>\n",
       "      <td>500</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 8, 'max_fea...</td>\n",
       "      <td>0.943662</td>\n",
       "      <td>0.964789</td>\n",
       "      <td>0.943662</td>\n",
       "      <td>0.950704</td>\n",
       "      <td>0.009959</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.215758</td>\n",
       "      <td>0.006945</td>\n",
       "      <td>0.016625</td>\n",
       "      <td>0.000939</td>\n",
       "      <td>gini</td>\n",
       "      <td>8</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>200</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 8, 'max_fea...</td>\n",
       "      <td>0.943662</td>\n",
       "      <td>0.957746</td>\n",
       "      <td>0.957746</td>\n",
       "      <td>0.953052</td>\n",
       "      <td>0.006640</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.576444</td>\n",
       "      <td>0.025412</td>\n",
       "      <td>0.038908</td>\n",
       "      <td>0.002812</td>\n",
       "      <td>gini</td>\n",
       "      <td>8</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>500</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 8, 'max_fea...</td>\n",
       "      <td>0.936620</td>\n",
       "      <td>0.957746</td>\n",
       "      <td>0.950704</td>\n",
       "      <td>0.948357</td>\n",
       "      <td>0.008783</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.232707</td>\n",
       "      <td>0.024333</td>\n",
       "      <td>0.016285</td>\n",
       "      <td>0.000493</td>\n",
       "      <td>gini</td>\n",
       "      <td>8</td>\n",
       "      <td>log2</td>\n",
       "      <td>200</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 8, 'max_fea...</td>\n",
       "      <td>0.943662</td>\n",
       "      <td>0.964789</td>\n",
       "      <td>0.957746</td>\n",
       "      <td>0.955399</td>\n",
       "      <td>0.008783</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.563501</td>\n",
       "      <td>0.052253</td>\n",
       "      <td>0.038574</td>\n",
       "      <td>0.000952</td>\n",
       "      <td>gini</td>\n",
       "      <td>8</td>\n",
       "      <td>log2</td>\n",
       "      <td>500</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 8, 'max_fea...</td>\n",
       "      <td>0.943662</td>\n",
       "      <td>0.964789</td>\n",
       "      <td>0.950704</td>\n",
       "      <td>0.953052</td>\n",
       "      <td>0.008783</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.243363</td>\n",
       "      <td>0.010680</td>\n",
       "      <td>0.016282</td>\n",
       "      <td>0.000476</td>\n",
       "      <td>entropy</td>\n",
       "      <td>4</td>\n",
       "      <td>auto</td>\n",
       "      <td>200</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 4, 'max_...</td>\n",
       "      <td>0.929577</td>\n",
       "      <td>0.957746</td>\n",
       "      <td>0.957746</td>\n",
       "      <td>0.948357</td>\n",
       "      <td>0.013279</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.564167</td>\n",
       "      <td>0.006530</td>\n",
       "      <td>0.036563</td>\n",
       "      <td>0.000466</td>\n",
       "      <td>entropy</td>\n",
       "      <td>4</td>\n",
       "      <td>auto</td>\n",
       "      <td>500</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 4, 'max_...</td>\n",
       "      <td>0.929577</td>\n",
       "      <td>0.964789</td>\n",
       "      <td>0.964789</td>\n",
       "      <td>0.953052</td>\n",
       "      <td>0.016599</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.224715</td>\n",
       "      <td>0.001684</td>\n",
       "      <td>0.015308</td>\n",
       "      <td>0.000474</td>\n",
       "      <td>entropy</td>\n",
       "      <td>4</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>200</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 4, 'max_...</td>\n",
       "      <td>0.943662</td>\n",
       "      <td>0.964789</td>\n",
       "      <td>0.936620</td>\n",
       "      <td>0.948357</td>\n",
       "      <td>0.011970</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.643933</td>\n",
       "      <td>0.068921</td>\n",
       "      <td>0.047872</td>\n",
       "      <td>0.012796</td>\n",
       "      <td>entropy</td>\n",
       "      <td>4</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>500</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 4, 'max_...</td>\n",
       "      <td>0.929577</td>\n",
       "      <td>0.957746</td>\n",
       "      <td>0.957746</td>\n",
       "      <td>0.948357</td>\n",
       "      <td>0.013279</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.218764</td>\n",
       "      <td>0.006120</td>\n",
       "      <td>0.015616</td>\n",
       "      <td>0.000468</td>\n",
       "      <td>entropy</td>\n",
       "      <td>4</td>\n",
       "      <td>log2</td>\n",
       "      <td>200</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 4, 'max_...</td>\n",
       "      <td>0.929577</td>\n",
       "      <td>0.964789</td>\n",
       "      <td>0.964789</td>\n",
       "      <td>0.953052</td>\n",
       "      <td>0.016599</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.538904</td>\n",
       "      <td>0.008186</td>\n",
       "      <td>0.038554</td>\n",
       "      <td>0.001257</td>\n",
       "      <td>entropy</td>\n",
       "      <td>4</td>\n",
       "      <td>log2</td>\n",
       "      <td>500</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 4, 'max_...</td>\n",
       "      <td>0.929577</td>\n",
       "      <td>0.957746</td>\n",
       "      <td>0.950704</td>\n",
       "      <td>0.946009</td>\n",
       "      <td>0.011970</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.227081</td>\n",
       "      <td>0.005891</td>\n",
       "      <td>0.015278</td>\n",
       "      <td>0.000465</td>\n",
       "      <td>entropy</td>\n",
       "      <td>5</td>\n",
       "      <td>auto</td>\n",
       "      <td>200</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 5, 'max_...</td>\n",
       "      <td>0.936620</td>\n",
       "      <td>0.957746</td>\n",
       "      <td>0.943662</td>\n",
       "      <td>0.946009</td>\n",
       "      <td>0.008783</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.567475</td>\n",
       "      <td>0.008024</td>\n",
       "      <td>0.036573</td>\n",
       "      <td>0.000473</td>\n",
       "      <td>entropy</td>\n",
       "      <td>5</td>\n",
       "      <td>auto</td>\n",
       "      <td>500</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 5, 'max_...</td>\n",
       "      <td>0.943662</td>\n",
       "      <td>0.957746</td>\n",
       "      <td>0.957746</td>\n",
       "      <td>0.953052</td>\n",
       "      <td>0.006640</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.226400</td>\n",
       "      <td>0.002147</td>\n",
       "      <td>0.015289</td>\n",
       "      <td>0.000481</td>\n",
       "      <td>entropy</td>\n",
       "      <td>5</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>200</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 5, 'max_...</td>\n",
       "      <td>0.943662</td>\n",
       "      <td>0.957746</td>\n",
       "      <td>0.936620</td>\n",
       "      <td>0.946009</td>\n",
       "      <td>0.008783</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.559534</td>\n",
       "      <td>0.004279</td>\n",
       "      <td>0.035595</td>\n",
       "      <td>0.000471</td>\n",
       "      <td>entropy</td>\n",
       "      <td>5</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>500</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 5, 'max_...</td>\n",
       "      <td>0.950704</td>\n",
       "      <td>0.957746</td>\n",
       "      <td>0.964789</td>\n",
       "      <td>0.957746</td>\n",
       "      <td>0.005750</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.214100</td>\n",
       "      <td>0.002606</td>\n",
       "      <td>0.015948</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>entropy</td>\n",
       "      <td>5</td>\n",
       "      <td>log2</td>\n",
       "      <td>200</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 5, 'max_...</td>\n",
       "      <td>0.950704</td>\n",
       "      <td>0.957746</td>\n",
       "      <td>0.957746</td>\n",
       "      <td>0.955399</td>\n",
       "      <td>0.003320</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.533564</td>\n",
       "      <td>0.002944</td>\n",
       "      <td>0.035920</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>entropy</td>\n",
       "      <td>5</td>\n",
       "      <td>log2</td>\n",
       "      <td>500</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 5, 'max_...</td>\n",
       "      <td>0.929577</td>\n",
       "      <td>0.964789</td>\n",
       "      <td>0.957746</td>\n",
       "      <td>0.950704</td>\n",
       "      <td>0.015213</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.224398</td>\n",
       "      <td>0.002920</td>\n",
       "      <td>0.014953</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>entropy</td>\n",
       "      <td>6</td>\n",
       "      <td>auto</td>\n",
       "      <td>200</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 6, 'max_...</td>\n",
       "      <td>0.950704</td>\n",
       "      <td>0.957746</td>\n",
       "      <td>0.950704</td>\n",
       "      <td>0.953052</td>\n",
       "      <td>0.003320</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.559180</td>\n",
       "      <td>0.004184</td>\n",
       "      <td>0.036567</td>\n",
       "      <td>0.000454</td>\n",
       "      <td>entropy</td>\n",
       "      <td>6</td>\n",
       "      <td>auto</td>\n",
       "      <td>500</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 6, 'max_...</td>\n",
       "      <td>0.936620</td>\n",
       "      <td>0.957746</td>\n",
       "      <td>0.957746</td>\n",
       "      <td>0.950704</td>\n",
       "      <td>0.009959</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.225065</td>\n",
       "      <td>0.002602</td>\n",
       "      <td>0.015618</td>\n",
       "      <td>0.000465</td>\n",
       "      <td>entropy</td>\n",
       "      <td>6</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>200</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 6, 'max_...</td>\n",
       "      <td>0.950704</td>\n",
       "      <td>0.957746</td>\n",
       "      <td>0.971831</td>\n",
       "      <td>0.960094</td>\n",
       "      <td>0.008783</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.561827</td>\n",
       "      <td>0.006130</td>\n",
       "      <td>0.036572</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>entropy</td>\n",
       "      <td>6</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>500</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 6, 'max_...</td>\n",
       "      <td>0.950704</td>\n",
       "      <td>0.964789</td>\n",
       "      <td>0.964789</td>\n",
       "      <td>0.960094</td>\n",
       "      <td>0.006640</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.213097</td>\n",
       "      <td>0.001695</td>\n",
       "      <td>0.014960</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>entropy</td>\n",
       "      <td>6</td>\n",
       "      <td>log2</td>\n",
       "      <td>200</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 6, 'max_...</td>\n",
       "      <td>0.950704</td>\n",
       "      <td>0.964789</td>\n",
       "      <td>0.950704</td>\n",
       "      <td>0.955399</td>\n",
       "      <td>0.006640</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.530588</td>\n",
       "      <td>0.003539</td>\n",
       "      <td>0.036236</td>\n",
       "      <td>0.000470</td>\n",
       "      <td>entropy</td>\n",
       "      <td>6</td>\n",
       "      <td>log2</td>\n",
       "      <td>500</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 6, 'max_...</td>\n",
       "      <td>0.943662</td>\n",
       "      <td>0.964789</td>\n",
       "      <td>0.957746</td>\n",
       "      <td>0.955399</td>\n",
       "      <td>0.008783</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.226069</td>\n",
       "      <td>0.001236</td>\n",
       "      <td>0.015275</td>\n",
       "      <td>0.000462</td>\n",
       "      <td>entropy</td>\n",
       "      <td>7</td>\n",
       "      <td>auto</td>\n",
       "      <td>200</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 7, 'max_...</td>\n",
       "      <td>0.943662</td>\n",
       "      <td>0.964789</td>\n",
       "      <td>0.957746</td>\n",
       "      <td>0.955399</td>\n",
       "      <td>0.008783</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.561838</td>\n",
       "      <td>0.004638</td>\n",
       "      <td>0.036562</td>\n",
       "      <td>0.000480</td>\n",
       "      <td>entropy</td>\n",
       "      <td>7</td>\n",
       "      <td>auto</td>\n",
       "      <td>500</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 7, 'max_...</td>\n",
       "      <td>0.943662</td>\n",
       "      <td>0.957746</td>\n",
       "      <td>0.957746</td>\n",
       "      <td>0.953052</td>\n",
       "      <td>0.006640</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.236393</td>\n",
       "      <td>0.005338</td>\n",
       "      <td>0.016597</td>\n",
       "      <td>0.000941</td>\n",
       "      <td>entropy</td>\n",
       "      <td>7</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>200</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 7, 'max_...</td>\n",
       "      <td>0.964789</td>\n",
       "      <td>0.957746</td>\n",
       "      <td>0.964789</td>\n",
       "      <td>0.962441</td>\n",
       "      <td>0.003320</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.632644</td>\n",
       "      <td>0.013850</td>\n",
       "      <td>0.038225</td>\n",
       "      <td>0.002040</td>\n",
       "      <td>entropy</td>\n",
       "      <td>7</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>500</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 7, 'max_...</td>\n",
       "      <td>0.950704</td>\n",
       "      <td>0.957746</td>\n",
       "      <td>0.950704</td>\n",
       "      <td>0.953052</td>\n",
       "      <td>0.003320</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.224074</td>\n",
       "      <td>0.008989</td>\n",
       "      <td>0.016293</td>\n",
       "      <td>0.000468</td>\n",
       "      <td>entropy</td>\n",
       "      <td>7</td>\n",
       "      <td>log2</td>\n",
       "      <td>200</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 7, 'max_...</td>\n",
       "      <td>0.943662</td>\n",
       "      <td>0.964789</td>\n",
       "      <td>0.950704</td>\n",
       "      <td>0.953052</td>\n",
       "      <td>0.008783</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.563809</td>\n",
       "      <td>0.004195</td>\n",
       "      <td>0.056197</td>\n",
       "      <td>0.025876</td>\n",
       "      <td>entropy</td>\n",
       "      <td>7</td>\n",
       "      <td>log2</td>\n",
       "      <td>500</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 7, 'max_...</td>\n",
       "      <td>0.950704</td>\n",
       "      <td>0.964789</td>\n",
       "      <td>0.957746</td>\n",
       "      <td>0.957746</td>\n",
       "      <td>0.005750</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.234027</td>\n",
       "      <td>0.007740</td>\n",
       "      <td>0.015632</td>\n",
       "      <td>0.000456</td>\n",
       "      <td>entropy</td>\n",
       "      <td>8</td>\n",
       "      <td>auto</td>\n",
       "      <td>200</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 8, 'max_...</td>\n",
       "      <td>0.950704</td>\n",
       "      <td>0.964789</td>\n",
       "      <td>0.936620</td>\n",
       "      <td>0.950704</td>\n",
       "      <td>0.011500</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0.564494</td>\n",
       "      <td>0.012799</td>\n",
       "      <td>0.035907</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>entropy</td>\n",
       "      <td>8</td>\n",
       "      <td>auto</td>\n",
       "      <td>500</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 8, 'max_...</td>\n",
       "      <td>0.950704</td>\n",
       "      <td>0.957746</td>\n",
       "      <td>0.957746</td>\n",
       "      <td>0.955399</td>\n",
       "      <td>0.003320</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.225737</td>\n",
       "      <td>0.002859</td>\n",
       "      <td>0.015285</td>\n",
       "      <td>0.000475</td>\n",
       "      <td>entropy</td>\n",
       "      <td>8</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>200</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 8, 'max_...</td>\n",
       "      <td>0.936620</td>\n",
       "      <td>0.957746</td>\n",
       "      <td>0.957746</td>\n",
       "      <td>0.950704</td>\n",
       "      <td>0.009959</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0.560505</td>\n",
       "      <td>0.005338</td>\n",
       "      <td>0.035897</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>entropy</td>\n",
       "      <td>8</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>500</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 8, 'max_...</td>\n",
       "      <td>0.943662</td>\n",
       "      <td>0.964789</td>\n",
       "      <td>0.957746</td>\n",
       "      <td>0.955399</td>\n",
       "      <td>0.008783</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.214423</td>\n",
       "      <td>0.002454</td>\n",
       "      <td>0.015632</td>\n",
       "      <td>0.000475</td>\n",
       "      <td>entropy</td>\n",
       "      <td>8</td>\n",
       "      <td>log2</td>\n",
       "      <td>200</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 8, 'max_...</td>\n",
       "      <td>0.943662</td>\n",
       "      <td>0.957746</td>\n",
       "      <td>0.957746</td>\n",
       "      <td>0.953052</td>\n",
       "      <td>0.006640</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.534228</td>\n",
       "      <td>0.003308</td>\n",
       "      <td>0.036249</td>\n",
       "      <td>0.000463</td>\n",
       "      <td>entropy</td>\n",
       "      <td>8</td>\n",
       "      <td>log2</td>\n",
       "      <td>500</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 8, 'max_...</td>\n",
       "      <td>0.957746</td>\n",
       "      <td>0.964789</td>\n",
       "      <td>0.964789</td>\n",
       "      <td>0.962441</td>\n",
       "      <td>0.003320</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        0.226199      0.026110         0.017074        0.002033   \n",
       "1        0.697335      0.067470         0.045212        0.004485   \n",
       "2        0.277591      0.009952         0.020622        0.005886   \n",
       "3        0.619287      0.103671         0.045647        0.013045   \n",
       "4        0.278919      0.023116         0.016957        0.000002   \n",
       "5        0.557188      0.042835         0.038884        0.001608   \n",
       "6        0.215087      0.007390         0.015968        0.000016   \n",
       "7        0.711097      0.020536         0.055179        0.022341   \n",
       "8        0.215438      0.012930         0.015287        0.000474   \n",
       "9        0.560166      0.041990         0.038233        0.000938   \n",
       "10       0.202106      0.003088         0.016301        0.000934   \n",
       "11       0.502330      0.001251         0.037891        0.001612   \n",
       "12       0.224067      0.006582         0.016962        0.000838   \n",
       "13       0.562148      0.023813         0.043212        0.004903   \n",
       "14       0.232375      0.029730         0.015629        0.000454   \n",
       "15       0.524598      0.009860         0.036898        0.001407   \n",
       "16       0.196468      0.002926         0.015634        0.000938   \n",
       "17       0.501656      0.007837         0.036569        0.000940   \n",
       "18       0.207115      0.001883         0.015291        0.000471   \n",
       "19       0.548866      0.047065         0.036235        0.000472   \n",
       "20       0.213430      0.004958         0.016956        0.001409   \n",
       "21       0.619333      0.057127         0.041207        0.004986   \n",
       "22       0.203461      0.002954         0.015627        0.000478   \n",
       "23       0.508293      0.019304         0.036919        0.000013   \n",
       "24       0.229706      0.018327         0.016623        0.001255   \n",
       "25       0.558179      0.013034         0.037559        0.001244   \n",
       "26       0.215758      0.006945         0.016625        0.000939   \n",
       "27       0.576444      0.025412         0.038908        0.002812   \n",
       "28       0.232707      0.024333         0.016285        0.000493   \n",
       "29       0.563501      0.052253         0.038574        0.000952   \n",
       "30       0.243363      0.010680         0.016282        0.000476   \n",
       "31       0.564167      0.006530         0.036563        0.000466   \n",
       "32       0.224715      0.001684         0.015308        0.000474   \n",
       "33       0.643933      0.068921         0.047872        0.012796   \n",
       "34       0.218764      0.006120         0.015616        0.000468   \n",
       "35       0.538904      0.008186         0.038554        0.001257   \n",
       "36       0.227081      0.005891         0.015278        0.000465   \n",
       "37       0.567475      0.008024         0.036573        0.000473   \n",
       "38       0.226400      0.002147         0.015289        0.000481   \n",
       "39       0.559534      0.004279         0.035595        0.000471   \n",
       "40       0.214100      0.002606         0.015948        0.000013   \n",
       "41       0.533564      0.002944         0.035920        0.000012   \n",
       "42       0.224398      0.002920         0.014953        0.000010   \n",
       "43       0.559180      0.004184         0.036567        0.000454   \n",
       "44       0.225065      0.002602         0.015618        0.000465   \n",
       "45       0.561827      0.006130         0.036572        0.000488   \n",
       "46       0.213097      0.001695         0.014960        0.000000   \n",
       "47       0.530588      0.003539         0.036236        0.000470   \n",
       "48       0.226069      0.001236         0.015275        0.000462   \n",
       "49       0.561838      0.004638         0.036562        0.000480   \n",
       "50       0.236393      0.005338         0.016597        0.000941   \n",
       "51       0.632644      0.013850         0.038225        0.002040   \n",
       "52       0.224074      0.008989         0.016293        0.000468   \n",
       "53       0.563809      0.004195         0.056197        0.025876   \n",
       "54       0.234027      0.007740         0.015632        0.000456   \n",
       "55       0.564494      0.012799         0.035907        0.000014   \n",
       "56       0.225737      0.002859         0.015285        0.000475   \n",
       "57       0.560505      0.005338         0.035897        0.000019   \n",
       "58       0.214423      0.002454         0.015632        0.000475   \n",
       "59       0.534228      0.003308         0.036249        0.000463   \n",
       "\n",
       "   param_criterion param_max_depth param_max_features param_n_estimators  \\\n",
       "0             gini               4               auto                200   \n",
       "1             gini               4               auto                500   \n",
       "2             gini               4               sqrt                200   \n",
       "3             gini               4               sqrt                500   \n",
       "4             gini               4               log2                200   \n",
       "5             gini               4               log2                500   \n",
       "6             gini               5               auto                200   \n",
       "7             gini               5               auto                500   \n",
       "8             gini               5               sqrt                200   \n",
       "9             gini               5               sqrt                500   \n",
       "10            gini               5               log2                200   \n",
       "11            gini               5               log2                500   \n",
       "12            gini               6               auto                200   \n",
       "13            gini               6               auto                500   \n",
       "14            gini               6               sqrt                200   \n",
       "15            gini               6               sqrt                500   \n",
       "16            gini               6               log2                200   \n",
       "17            gini               6               log2                500   \n",
       "18            gini               7               auto                200   \n",
       "19            gini               7               auto                500   \n",
       "20            gini               7               sqrt                200   \n",
       "21            gini               7               sqrt                500   \n",
       "22            gini               7               log2                200   \n",
       "23            gini               7               log2                500   \n",
       "24            gini               8               auto                200   \n",
       "25            gini               8               auto                500   \n",
       "26            gini               8               sqrt                200   \n",
       "27            gini               8               sqrt                500   \n",
       "28            gini               8               log2                200   \n",
       "29            gini               8               log2                500   \n",
       "30         entropy               4               auto                200   \n",
       "31         entropy               4               auto                500   \n",
       "32         entropy               4               sqrt                200   \n",
       "33         entropy               4               sqrt                500   \n",
       "34         entropy               4               log2                200   \n",
       "35         entropy               4               log2                500   \n",
       "36         entropy               5               auto                200   \n",
       "37         entropy               5               auto                500   \n",
       "38         entropy               5               sqrt                200   \n",
       "39         entropy               5               sqrt                500   \n",
       "40         entropy               5               log2                200   \n",
       "41         entropy               5               log2                500   \n",
       "42         entropy               6               auto                200   \n",
       "43         entropy               6               auto                500   \n",
       "44         entropy               6               sqrt                200   \n",
       "45         entropy               6               sqrt                500   \n",
       "46         entropy               6               log2                200   \n",
       "47         entropy               6               log2                500   \n",
       "48         entropy               7               auto                200   \n",
       "49         entropy               7               auto                500   \n",
       "50         entropy               7               sqrt                200   \n",
       "51         entropy               7               sqrt                500   \n",
       "52         entropy               7               log2                200   \n",
       "53         entropy               7               log2                500   \n",
       "54         entropy               8               auto                200   \n",
       "55         entropy               8               auto                500   \n",
       "56         entropy               8               sqrt                200   \n",
       "57         entropy               8               sqrt                500   \n",
       "58         entropy               8               log2                200   \n",
       "59         entropy               8               log2                500   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0   {'criterion': 'gini', 'max_depth': 4, 'max_fea...           0.943662   \n",
       "1   {'criterion': 'gini', 'max_depth': 4, 'max_fea...           0.936620   \n",
       "2   {'criterion': 'gini', 'max_depth': 4, 'max_fea...           0.936620   \n",
       "3   {'criterion': 'gini', 'max_depth': 4, 'max_fea...           0.936620   \n",
       "4   {'criterion': 'gini', 'max_depth': 4, 'max_fea...           0.936620   \n",
       "5   {'criterion': 'gini', 'max_depth': 4, 'max_fea...           0.936620   \n",
       "6   {'criterion': 'gini', 'max_depth': 5, 'max_fea...           0.957746   \n",
       "7   {'criterion': 'gini', 'max_depth': 5, 'max_fea...           0.936620   \n",
       "8   {'criterion': 'gini', 'max_depth': 5, 'max_fea...           0.943662   \n",
       "9   {'criterion': 'gini', 'max_depth': 5, 'max_fea...           0.936620   \n",
       "10  {'criterion': 'gini', 'max_depth': 5, 'max_fea...           0.936620   \n",
       "11  {'criterion': 'gini', 'max_depth': 5, 'max_fea...           0.936620   \n",
       "12  {'criterion': 'gini', 'max_depth': 6, 'max_fea...           0.943662   \n",
       "13  {'criterion': 'gini', 'max_depth': 6, 'max_fea...           0.943662   \n",
       "14  {'criterion': 'gini', 'max_depth': 6, 'max_fea...           0.943662   \n",
       "15  {'criterion': 'gini', 'max_depth': 6, 'max_fea...           0.936620   \n",
       "16  {'criterion': 'gini', 'max_depth': 6, 'max_fea...           0.943662   \n",
       "17  {'criterion': 'gini', 'max_depth': 6, 'max_fea...           0.943662   \n",
       "18  {'criterion': 'gini', 'max_depth': 7, 'max_fea...           0.950704   \n",
       "19  {'criterion': 'gini', 'max_depth': 7, 'max_fea...           0.936620   \n",
       "20  {'criterion': 'gini', 'max_depth': 7, 'max_fea...           0.936620   \n",
       "21  {'criterion': 'gini', 'max_depth': 7, 'max_fea...           0.929577   \n",
       "22  {'criterion': 'gini', 'max_depth': 7, 'max_fea...           0.943662   \n",
       "23  {'criterion': 'gini', 'max_depth': 7, 'max_fea...           0.936620   \n",
       "24  {'criterion': 'gini', 'max_depth': 8, 'max_fea...           0.936620   \n",
       "25  {'criterion': 'gini', 'max_depth': 8, 'max_fea...           0.943662   \n",
       "26  {'criterion': 'gini', 'max_depth': 8, 'max_fea...           0.943662   \n",
       "27  {'criterion': 'gini', 'max_depth': 8, 'max_fea...           0.936620   \n",
       "28  {'criterion': 'gini', 'max_depth': 8, 'max_fea...           0.943662   \n",
       "29  {'criterion': 'gini', 'max_depth': 8, 'max_fea...           0.943662   \n",
       "30  {'criterion': 'entropy', 'max_depth': 4, 'max_...           0.929577   \n",
       "31  {'criterion': 'entropy', 'max_depth': 4, 'max_...           0.929577   \n",
       "32  {'criterion': 'entropy', 'max_depth': 4, 'max_...           0.943662   \n",
       "33  {'criterion': 'entropy', 'max_depth': 4, 'max_...           0.929577   \n",
       "34  {'criterion': 'entropy', 'max_depth': 4, 'max_...           0.929577   \n",
       "35  {'criterion': 'entropy', 'max_depth': 4, 'max_...           0.929577   \n",
       "36  {'criterion': 'entropy', 'max_depth': 5, 'max_...           0.936620   \n",
       "37  {'criterion': 'entropy', 'max_depth': 5, 'max_...           0.943662   \n",
       "38  {'criterion': 'entropy', 'max_depth': 5, 'max_...           0.943662   \n",
       "39  {'criterion': 'entropy', 'max_depth': 5, 'max_...           0.950704   \n",
       "40  {'criterion': 'entropy', 'max_depth': 5, 'max_...           0.950704   \n",
       "41  {'criterion': 'entropy', 'max_depth': 5, 'max_...           0.929577   \n",
       "42  {'criterion': 'entropy', 'max_depth': 6, 'max_...           0.950704   \n",
       "43  {'criterion': 'entropy', 'max_depth': 6, 'max_...           0.936620   \n",
       "44  {'criterion': 'entropy', 'max_depth': 6, 'max_...           0.950704   \n",
       "45  {'criterion': 'entropy', 'max_depth': 6, 'max_...           0.950704   \n",
       "46  {'criterion': 'entropy', 'max_depth': 6, 'max_...           0.950704   \n",
       "47  {'criterion': 'entropy', 'max_depth': 6, 'max_...           0.943662   \n",
       "48  {'criterion': 'entropy', 'max_depth': 7, 'max_...           0.943662   \n",
       "49  {'criterion': 'entropy', 'max_depth': 7, 'max_...           0.943662   \n",
       "50  {'criterion': 'entropy', 'max_depth': 7, 'max_...           0.964789   \n",
       "51  {'criterion': 'entropy', 'max_depth': 7, 'max_...           0.950704   \n",
       "52  {'criterion': 'entropy', 'max_depth': 7, 'max_...           0.943662   \n",
       "53  {'criterion': 'entropy', 'max_depth': 7, 'max_...           0.950704   \n",
       "54  {'criterion': 'entropy', 'max_depth': 8, 'max_...           0.950704   \n",
       "55  {'criterion': 'entropy', 'max_depth': 8, 'max_...           0.950704   \n",
       "56  {'criterion': 'entropy', 'max_depth': 8, 'max_...           0.936620   \n",
       "57  {'criterion': 'entropy', 'max_depth': 8, 'max_...           0.943662   \n",
       "58  {'criterion': 'entropy', 'max_depth': 8, 'max_...           0.943662   \n",
       "59  {'criterion': 'entropy', 'max_depth': 8, 'max_...           0.957746   \n",
       "\n",
       "    split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "0            0.957746           0.957746         0.953052        0.006640   \n",
       "1            0.957746           0.943662         0.946009        0.008783   \n",
       "2            0.957746           0.950704         0.948357        0.008783   \n",
       "3            0.957746           0.950704         0.948357        0.008783   \n",
       "4            0.957746           0.957746         0.950704        0.009959   \n",
       "5            0.957746           0.943662         0.946009        0.008783   \n",
       "6            0.964789           0.950704         0.957746        0.005750   \n",
       "7            0.957746           0.950704         0.948357        0.008783   \n",
       "8            0.950704           0.957746         0.950704        0.005750   \n",
       "9            0.957746           0.950704         0.948357        0.008783   \n",
       "10           0.950704           0.957746         0.948357        0.008783   \n",
       "11           0.964789           0.950704         0.950704        0.011500   \n",
       "12           0.964789           0.943662         0.950704        0.009959   \n",
       "13           0.957746           0.950704         0.950704        0.005750   \n",
       "14           0.964789           0.943662         0.950704        0.009959   \n",
       "15           0.957746           0.943662         0.946009        0.008783   \n",
       "16           0.964789           0.950704         0.953052        0.008783   \n",
       "17           0.957746           0.943662         0.948357        0.006640   \n",
       "18           0.950704           0.943662         0.948357        0.003320   \n",
       "19           0.964789           0.950704         0.950704        0.011500   \n",
       "20           0.957746           0.936620         0.943662        0.009959   \n",
       "21           0.957746           0.950704         0.946009        0.011970   \n",
       "22           0.964789           0.950704         0.953052        0.008783   \n",
       "23           0.957746           0.950704         0.948357        0.008783   \n",
       "24           0.957746           0.957746         0.950704        0.009959   \n",
       "25           0.964789           0.943662         0.950704        0.009959   \n",
       "26           0.957746           0.957746         0.953052        0.006640   \n",
       "27           0.957746           0.950704         0.948357        0.008783   \n",
       "28           0.964789           0.957746         0.955399        0.008783   \n",
       "29           0.964789           0.950704         0.953052        0.008783   \n",
       "30           0.957746           0.957746         0.948357        0.013279   \n",
       "31           0.964789           0.964789         0.953052        0.016599   \n",
       "32           0.964789           0.936620         0.948357        0.011970   \n",
       "33           0.957746           0.957746         0.948357        0.013279   \n",
       "34           0.964789           0.964789         0.953052        0.016599   \n",
       "35           0.957746           0.950704         0.946009        0.011970   \n",
       "36           0.957746           0.943662         0.946009        0.008783   \n",
       "37           0.957746           0.957746         0.953052        0.006640   \n",
       "38           0.957746           0.936620         0.946009        0.008783   \n",
       "39           0.957746           0.964789         0.957746        0.005750   \n",
       "40           0.957746           0.957746         0.955399        0.003320   \n",
       "41           0.964789           0.957746         0.950704        0.015213   \n",
       "42           0.957746           0.950704         0.953052        0.003320   \n",
       "43           0.957746           0.957746         0.950704        0.009959   \n",
       "44           0.957746           0.971831         0.960094        0.008783   \n",
       "45           0.964789           0.964789         0.960094        0.006640   \n",
       "46           0.964789           0.950704         0.955399        0.006640   \n",
       "47           0.964789           0.957746         0.955399        0.008783   \n",
       "48           0.964789           0.957746         0.955399        0.008783   \n",
       "49           0.957746           0.957746         0.953052        0.006640   \n",
       "50           0.957746           0.964789         0.962441        0.003320   \n",
       "51           0.957746           0.950704         0.953052        0.003320   \n",
       "52           0.964789           0.950704         0.953052        0.008783   \n",
       "53           0.964789           0.957746         0.957746        0.005750   \n",
       "54           0.964789           0.936620         0.950704        0.011500   \n",
       "55           0.957746           0.957746         0.955399        0.003320   \n",
       "56           0.957746           0.957746         0.950704        0.009959   \n",
       "57           0.964789           0.957746         0.955399        0.008783   \n",
       "58           0.957746           0.957746         0.953052        0.006640   \n",
       "59           0.964789           0.964789         0.962441        0.003320   \n",
       "\n",
       "    rank_test_score  \n",
       "0                17  \n",
       "1                53  \n",
       "2                41  \n",
       "3                41  \n",
       "4                28  \n",
       "5                53  \n",
       "6                 6  \n",
       "7                41  \n",
       "8                28  \n",
       "9                41  \n",
       "10               41  \n",
       "11               28  \n",
       "12               28  \n",
       "13               28  \n",
       "14               28  \n",
       "15               53  \n",
       "16               17  \n",
       "17               41  \n",
       "18               41  \n",
       "19               28  \n",
       "20               60  \n",
       "21               53  \n",
       "22               17  \n",
       "23               41  \n",
       "24               28  \n",
       "25               28  \n",
       "26               17  \n",
       "27               41  \n",
       "28                8  \n",
       "29               17  \n",
       "30               41  \n",
       "31               15  \n",
       "32               41  \n",
       "33               41  \n",
       "34               15  \n",
       "35               53  \n",
       "36               53  \n",
       "37               17  \n",
       "38               53  \n",
       "39                6  \n",
       "40                8  \n",
       "41               28  \n",
       "42               17  \n",
       "43               28  \n",
       "44                3  \n",
       "45                3  \n",
       "46                8  \n",
       "47                8  \n",
       "48                8  \n",
       "49               17  \n",
       "50                1  \n",
       "51               17  \n",
       "52               17  \n",
       "53                5  \n",
       "54               28  \n",
       "55                8  \n",
       "56               28  \n",
       "57                8  \n",
       "58               17  \n",
       "59                1  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuning_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "65f21768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 60 entries, 0 to 59\n",
      "Data columns (total 15 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   mean_fit_time       60 non-null     float64\n",
      " 1   std_fit_time        60 non-null     float64\n",
      " 2   mean_score_time     60 non-null     float64\n",
      " 3   std_score_time      60 non-null     float64\n",
      " 4   param_criterion     60 non-null     object \n",
      " 5   param_max_depth     60 non-null     object \n",
      " 6   param_max_features  60 non-null     object \n",
      " 7   param_n_estimators  60 non-null     object \n",
      " 8   params              60 non-null     object \n",
      " 9   split0_test_score   60 non-null     float64\n",
      " 10  split1_test_score   60 non-null     float64\n",
      " 11  split2_test_score   60 non-null     float64\n",
      " 12  mean_test_score     60 non-null     float64\n",
      " 13  std_test_score      60 non-null     float64\n",
      " 14  rank_test_score     60 non-null     int32  \n",
      "dtypes: float64(9), int32(1), object(5)\n",
      "memory usage: 6.9+ KB\n"
     ]
    }
   ],
   "source": [
    "tuning_result.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1b3b4209",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'entropy',\n",
       " 'max_depth': 7,\n",
       " 'max_features': 'sqrt',\n",
       " 'n_estimators': 200}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d7c3e856",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9624413145539906"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5e1bc40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf2=clf_grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2fa9aed5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(criterion='entropy', max_depth=7, max_features='sqrt',\n",
       "                       n_estimators=200)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1a616c3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(criterion='entropy', max_depth=7, max_features='sqrt',\n",
       "                       n_estimators=200)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf2.fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bd4bd310",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.972027972027972"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf2.score(xtest,ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa5549b2",
   "metadata": {},
   "source": [
    "# Randomized Search CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "458a6376",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid2={\n",
    "    'n_estimators': [200, 500],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'max_depth' : [4,5,6,7,8],\n",
    "    'criterion' :['gini', 'entropy']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6e74d56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e5d2686c",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_ran=RandomizedSearchCV(clf,param_grid2,cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "32233ac6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, estimator=RandomForestClassifier(),\n",
       "                   param_distributions={'criterion': ['gini', 'entropy'],\n",
       "                                        'max_depth': [4, 5, 6, 7, 8],\n",
       "                                        'max_features': ['auto', 'sqrt',\n",
       "                                                         'log2'],\n",
       "                                        'n_estimators': [200, 500]})"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_ran.fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2ca55d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "Random_Tuning_Result=pd.DataFrame(clf_ran.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "25c48d6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_criterion</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.195480</td>\n",
       "      <td>0.002134</td>\n",
       "      <td>0.015613</td>\n",
       "      <td>0.000447</td>\n",
       "      <td>200</td>\n",
       "      <td>log2</td>\n",
       "      <td>4</td>\n",
       "      <td>gini</td>\n",
       "      <td>{'n_estimators': 200, 'max_features': 'log2', ...</td>\n",
       "      <td>0.936620</td>\n",
       "      <td>0.950704</td>\n",
       "      <td>0.943662</td>\n",
       "      <td>0.943662</td>\n",
       "      <td>0.005750</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.503655</td>\n",
       "      <td>0.003550</td>\n",
       "      <td>0.037242</td>\n",
       "      <td>0.000464</td>\n",
       "      <td>500</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>4</td>\n",
       "      <td>gini</td>\n",
       "      <td>{'n_estimators': 500, 'max_features': 'sqrt', ...</td>\n",
       "      <td>0.936620</td>\n",
       "      <td>0.950704</td>\n",
       "      <td>0.943662</td>\n",
       "      <td>0.943662</td>\n",
       "      <td>0.005750</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.214746</td>\n",
       "      <td>0.001251</td>\n",
       "      <td>0.015628</td>\n",
       "      <td>0.000473</td>\n",
       "      <td>200</td>\n",
       "      <td>log2</td>\n",
       "      <td>5</td>\n",
       "      <td>entropy</td>\n",
       "      <td>{'n_estimators': 200, 'max_features': 'log2', ...</td>\n",
       "      <td>0.936620</td>\n",
       "      <td>0.964789</td>\n",
       "      <td>0.957746</td>\n",
       "      <td>0.953052</td>\n",
       "      <td>0.011970</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.201121</td>\n",
       "      <td>0.001898</td>\n",
       "      <td>0.015293</td>\n",
       "      <td>0.000455</td>\n",
       "      <td>200</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>4</td>\n",
       "      <td>gini</td>\n",
       "      <td>{'n_estimators': 200, 'max_features': 'sqrt', ...</td>\n",
       "      <td>0.936620</td>\n",
       "      <td>0.957746</td>\n",
       "      <td>0.950704</td>\n",
       "      <td>0.948357</td>\n",
       "      <td>0.008783</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.509622</td>\n",
       "      <td>0.003742</td>\n",
       "      <td>0.037248</td>\n",
       "      <td>0.001252</td>\n",
       "      <td>500</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>6</td>\n",
       "      <td>gini</td>\n",
       "      <td>{'n_estimators': 500, 'max_features': 'sqrt', ...</td>\n",
       "      <td>0.943662</td>\n",
       "      <td>0.957746</td>\n",
       "      <td>0.950704</td>\n",
       "      <td>0.950704</td>\n",
       "      <td>0.005750</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.215098</td>\n",
       "      <td>0.001251</td>\n",
       "      <td>0.015630</td>\n",
       "      <td>0.000465</td>\n",
       "      <td>200</td>\n",
       "      <td>log2</td>\n",
       "      <td>7</td>\n",
       "      <td>entropy</td>\n",
       "      <td>{'n_estimators': 200, 'max_features': 'log2', ...</td>\n",
       "      <td>0.950704</td>\n",
       "      <td>0.964789</td>\n",
       "      <td>0.950704</td>\n",
       "      <td>0.955399</td>\n",
       "      <td>0.006640</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.573807</td>\n",
       "      <td>0.012000</td>\n",
       "      <td>0.038888</td>\n",
       "      <td>0.002143</td>\n",
       "      <td>500</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>7</td>\n",
       "      <td>entropy</td>\n",
       "      <td>{'n_estimators': 500, 'max_features': 'sqrt', ...</td>\n",
       "      <td>0.964789</td>\n",
       "      <td>0.964789</td>\n",
       "      <td>0.957746</td>\n",
       "      <td>0.962441</td>\n",
       "      <td>0.003320</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.540879</td>\n",
       "      <td>0.029399</td>\n",
       "      <td>0.038239</td>\n",
       "      <td>0.000465</td>\n",
       "      <td>500</td>\n",
       "      <td>auto</td>\n",
       "      <td>5</td>\n",
       "      <td>gini</td>\n",
       "      <td>{'n_estimators': 500, 'max_features': 'auto', ...</td>\n",
       "      <td>0.936620</td>\n",
       "      <td>0.957746</td>\n",
       "      <td>0.950704</td>\n",
       "      <td>0.948357</td>\n",
       "      <td>0.008783</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.498667</td>\n",
       "      <td>0.007067</td>\n",
       "      <td>0.036902</td>\n",
       "      <td>0.000807</td>\n",
       "      <td>500</td>\n",
       "      <td>log2</td>\n",
       "      <td>7</td>\n",
       "      <td>gini</td>\n",
       "      <td>{'n_estimators': 500, 'max_features': 'log2', ...</td>\n",
       "      <td>0.943662</td>\n",
       "      <td>0.964789</td>\n",
       "      <td>0.950704</td>\n",
       "      <td>0.953052</td>\n",
       "      <td>0.008783</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.546202</td>\n",
       "      <td>0.005293</td>\n",
       "      <td>0.037898</td>\n",
       "      <td>0.000806</td>\n",
       "      <td>500</td>\n",
       "      <td>log2</td>\n",
       "      <td>4</td>\n",
       "      <td>entropy</td>\n",
       "      <td>{'n_estimators': 500, 'max_features': 'log2', ...</td>\n",
       "      <td>0.936620</td>\n",
       "      <td>0.964789</td>\n",
       "      <td>0.950704</td>\n",
       "      <td>0.950704</td>\n",
       "      <td>0.011500</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.195480      0.002134         0.015613        0.000447   \n",
       "1       0.503655      0.003550         0.037242        0.000464   \n",
       "2       0.214746      0.001251         0.015628        0.000473   \n",
       "3       0.201121      0.001898         0.015293        0.000455   \n",
       "4       0.509622      0.003742         0.037248        0.001252   \n",
       "5       0.215098      0.001251         0.015630        0.000465   \n",
       "6       0.573807      0.012000         0.038888        0.002143   \n",
       "7       0.540879      0.029399         0.038239        0.000465   \n",
       "8       0.498667      0.007067         0.036902        0.000807   \n",
       "9       0.546202      0.005293         0.037898        0.000806   \n",
       "\n",
       "  param_n_estimators param_max_features param_max_depth param_criterion  \\\n",
       "0                200               log2               4            gini   \n",
       "1                500               sqrt               4            gini   \n",
       "2                200               log2               5         entropy   \n",
       "3                200               sqrt               4            gini   \n",
       "4                500               sqrt               6            gini   \n",
       "5                200               log2               7         entropy   \n",
       "6                500               sqrt               7         entropy   \n",
       "7                500               auto               5            gini   \n",
       "8                500               log2               7            gini   \n",
       "9                500               log2               4         entropy   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "0  {'n_estimators': 200, 'max_features': 'log2', ...           0.936620   \n",
       "1  {'n_estimators': 500, 'max_features': 'sqrt', ...           0.936620   \n",
       "2  {'n_estimators': 200, 'max_features': 'log2', ...           0.936620   \n",
       "3  {'n_estimators': 200, 'max_features': 'sqrt', ...           0.936620   \n",
       "4  {'n_estimators': 500, 'max_features': 'sqrt', ...           0.943662   \n",
       "5  {'n_estimators': 200, 'max_features': 'log2', ...           0.950704   \n",
       "6  {'n_estimators': 500, 'max_features': 'sqrt', ...           0.964789   \n",
       "7  {'n_estimators': 500, 'max_features': 'auto', ...           0.936620   \n",
       "8  {'n_estimators': 500, 'max_features': 'log2', ...           0.943662   \n",
       "9  {'n_estimators': 500, 'max_features': 'log2', ...           0.936620   \n",
       "\n",
       "   split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "0           0.950704           0.943662         0.943662        0.005750   \n",
       "1           0.950704           0.943662         0.943662        0.005750   \n",
       "2           0.964789           0.957746         0.953052        0.011970   \n",
       "3           0.957746           0.950704         0.948357        0.008783   \n",
       "4           0.957746           0.950704         0.950704        0.005750   \n",
       "5           0.964789           0.950704         0.955399        0.006640   \n",
       "6           0.964789           0.957746         0.962441        0.003320   \n",
       "7           0.957746           0.950704         0.948357        0.008783   \n",
       "8           0.964789           0.950704         0.953052        0.008783   \n",
       "9           0.964789           0.950704         0.950704        0.011500   \n",
       "\n",
       "   rank_test_score  \n",
       "0                9  \n",
       "1                9  \n",
       "2                3  \n",
       "3                7  \n",
       "4                5  \n",
       "5                2  \n",
       "6                1  \n",
       "7                7  \n",
       "8                4  \n",
       "9                5  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Random_Tuning_Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "af9d0b9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 500,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_depth': 7,\n",
       " 'criterion': 'entropy'}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_ran.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9ffec496",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.972027972027972"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_ran.score(xtest,ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "410796a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf3=clf_ran.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e9d1d96f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(criterion='entropy', max_depth=7, max_features='sqrt',\n",
       "                       n_estimators=500)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf3.fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c30b7301",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.972027972027972"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf3.score(xtest,ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e745f44",
   "metadata": {},
   "source": [
    "# HyperParameter Tuning For XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "83f955e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n",
      "Retrieving notices: ...working... done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda install -c conda-forge xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "08369ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f191ebf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_clf=XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "75b6fdfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:54:19] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "              gamma=0, gpu_id=-1, importance_type=None,\n",
       "              interaction_constraints='', learning_rate=0.300000012,\n",
       "              max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints='()', n_estimators=100, n_jobs=4,\n",
       "              num_parallel_tree=1, predictor='auto', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg_clf.fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "180f53f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['B', 'M', 'M', 'B', 'B', 'M', 'M', 'M', 'M', 'B', 'B', 'M', 'B',\n",
       "       'M', 'B', 'M', 'B', 'B', 'B', 'M', 'B', 'B', 'M', 'B', 'B', 'B',\n",
       "       'B', 'B', 'B', 'M', 'B', 'B', 'B', 'B', 'B', 'B', 'M', 'B', 'M',\n",
       "       'B', 'B', 'M', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'M', 'M',\n",
       "       'B', 'B', 'B', 'B', 'B', 'M', 'M', 'B', 'B', 'M', 'M', 'B', 'B',\n",
       "       'B', 'M', 'M', 'B', 'B', 'M', 'M', 'B', 'M', 'B', 'B', 'B', 'B',\n",
       "       'B', 'B', 'M', 'B', 'B', 'M', 'M', 'M', 'M', 'M', 'B', 'B', 'B',\n",
       "       'B', 'B', 'B', 'B', 'B', 'M', 'M', 'B', 'M', 'M', 'B', 'M', 'M',\n",
       "       'B', 'B', 'B', 'M', 'B', 'B', 'M', 'B', 'B', 'M', 'B', 'M', 'B',\n",
       "       'B', 'B', 'M', 'B', 'B', 'B', 'M', 'B', 'M', 'M', 'B', 'B', 'M',\n",
       "       'M', 'M', 'B', 'B', 'B', 'M', 'M', 'B', 'B', 'M', 'B', 'M', 'B'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg_clf.predict(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "bf626b68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.965034965034965"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg_clf.score(xtest,ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "aecc44dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "              gamma=0, gpu_id=-1, importance_type=None,\n",
       "              interaction_constraints='', learning_rate=0.300000012,\n",
       "              max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints='()', n_estimators=100, n_jobs=4,\n",
       "              num_parallel_tree=1, predictor='auto', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg_clf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef2eff0",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning of XGBoost with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6a8da8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"max_depth\": [3, 4, 5, 7],\n",
    "    \"learning_rate\": [0.1, 0.01, 0.05],\n",
    "    \"gamma\": [0, 0.25, 1],\n",
    "    \"reg_lambda\": [0, 1, 10],\n",
    "    \"scale_pos_weight\": [1, 3, 5],\n",
    "    \"subsample\": [0.8],\n",
    "    \"colsample_bytree\": [0.5],\n",
    "}              #subsample and colsample_bytree to recommended values to speed things up and prevent overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "857beb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1beeb9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Init Grid Search\n",
    "xg_grid_cv = GridSearchCV(xg_clf, param_grid, n_jobs=-1, cv=3, scoring=\"roc_auc\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f09c2c26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:54:48] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                                     colsample_bylevel=1, colsample_bynode=1,\n",
       "                                     colsample_bytree=1,\n",
       "                                     enable_categorical=False, gamma=0,\n",
       "                                     gpu_id=-1, importance_type=None,\n",
       "                                     interaction_constraints='',\n",
       "                                     learning_rate=0.300000012,\n",
       "                                     max_delta_step=0, max_depth=6,\n",
       "                                     min_child_weight=1, missing=nan,\n",
       "                                     monotone_constraints='()',\n",
       "                                     n_estimators=10...\n",
       "                                     num_parallel_tree=1, predictor='auto',\n",
       "                                     random_state=0, reg_alpha=0, reg_lambda=1,\n",
       "                                     scale_pos_weight=1, subsample=1,\n",
       "                                     tree_method='exact', validate_parameters=1,\n",
       "                                     verbosity=None),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'colsample_bytree': [0.5], 'gamma': [0, 0.25, 1],\n",
       "                         'learning_rate': [0.1, 0.01, 0.05],\n",
       "                         'max_depth': [3, 4, 5, 7], 'reg_lambda': [0, 1, 10],\n",
       "                         'scale_pos_weight': [1, 3, 5], 'subsample': [0.8]},\n",
       "             scoring='roc_auc')"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit\n",
    "xg_grid_cv.fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f0df702b",
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_grid_result=pd.DataFrame(xg_grid_cv.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f054d327",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_reg_lambda</th>\n",
       "      <th>param_scale_pos_weight</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.062484</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.015622</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'colsample_bytree': 0.5, 'gamma': 0, 'learnin...</td>\n",
       "      <td>0.998291</td>\n",
       "      <td>0.977740</td>\n",
       "      <td>0.988552</td>\n",
       "      <td>0.988194</td>\n",
       "      <td>0.008394</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.067692</td>\n",
       "      <td>7.362886e-03</td>\n",
       "      <td>0.005207</td>\n",
       "      <td>0.007364</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'colsample_bytree': 0.5, 'gamma': 0, 'learnin...</td>\n",
       "      <td>0.998077</td>\n",
       "      <td>0.973924</td>\n",
       "      <td>0.991308</td>\n",
       "      <td>0.987770</td>\n",
       "      <td>0.010173</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.062485</td>\n",
       "      <td>2.809790e-06</td>\n",
       "      <td>0.005209</td>\n",
       "      <td>0.007366</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'colsample_bytree': 0.5, 'gamma': 0, 'learnin...</td>\n",
       "      <td>0.997222</td>\n",
       "      <td>0.976892</td>\n",
       "      <td>0.989824</td>\n",
       "      <td>0.987979</td>\n",
       "      <td>0.008402</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.062481</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.015626</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'colsample_bytree': 0.5, 'gamma': 0, 'learnin...</td>\n",
       "      <td>0.997863</td>\n",
       "      <td>0.976468</td>\n",
       "      <td>0.989612</td>\n",
       "      <td>0.987981</td>\n",
       "      <td>0.008810</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.062480</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'colsample_bytree': 0.5, 'gamma': 0, 'learnin...</td>\n",
       "      <td>0.998291</td>\n",
       "      <td>0.979648</td>\n",
       "      <td>0.989188</td>\n",
       "      <td>0.989042</td>\n",
       "      <td>0.007611</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>0.098935</td>\n",
       "      <td>7.364178e-03</td>\n",
       "      <td>0.005207</td>\n",
       "      <td>0.007364</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'colsample_bytree': 0.5, 'gamma': 1, 'learnin...</td>\n",
       "      <td>0.996795</td>\n",
       "      <td>0.977104</td>\n",
       "      <td>0.988976</td>\n",
       "      <td>0.987625</td>\n",
       "      <td>0.008095</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>0.098934</td>\n",
       "      <td>7.364965e-03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'colsample_bytree': 0.5, 'gamma': 1, 'learnin...</td>\n",
       "      <td>0.996795</td>\n",
       "      <td>0.975620</td>\n",
       "      <td>0.989188</td>\n",
       "      <td>0.987201</td>\n",
       "      <td>0.008758</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>0.083313</td>\n",
       "      <td>7.364459e-03</td>\n",
       "      <td>0.010415</td>\n",
       "      <td>0.007365</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'colsample_bytree': 0.5, 'gamma': 1, 'learnin...</td>\n",
       "      <td>0.992308</td>\n",
       "      <td>0.976256</td>\n",
       "      <td>0.985796</td>\n",
       "      <td>0.984787</td>\n",
       "      <td>0.006592</td>\n",
       "      <td>237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>0.093727</td>\n",
       "      <td>4.495664e-07</td>\n",
       "      <td>0.010414</td>\n",
       "      <td>0.007364</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'colsample_bytree': 0.5, 'gamma': 1, 'learnin...</td>\n",
       "      <td>0.996581</td>\n",
       "      <td>0.975832</td>\n",
       "      <td>0.989400</td>\n",
       "      <td>0.987271</td>\n",
       "      <td>0.008604</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>0.088521</td>\n",
       "      <td>1.472774e-02</td>\n",
       "      <td>0.005207</td>\n",
       "      <td>0.007364</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'colsample_bytree': 0.5, 'gamma': 1, 'learnin...</td>\n",
       "      <td>0.995726</td>\n",
       "      <td>0.975832</td>\n",
       "      <td>0.990460</td>\n",
       "      <td>0.987340</td>\n",
       "      <td>0.008416</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>324 rows Ã— 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0         0.062484  0.000000e+00         0.015622        0.000000   \n",
       "1         0.067692  7.362886e-03         0.005207        0.007364   \n",
       "2         0.062485  2.809790e-06         0.005209        0.007366   \n",
       "3         0.062481  0.000000e+00         0.015626        0.000000   \n",
       "4         0.062480  0.000000e+00         0.000000        0.000000   \n",
       "..             ...           ...              ...             ...   \n",
       "319       0.098935  7.364178e-03         0.005207        0.007364   \n",
       "320       0.098934  7.364965e-03         0.000000        0.000000   \n",
       "321       0.083313  7.364459e-03         0.010415        0.007365   \n",
       "322       0.093727  4.495664e-07         0.010414        0.007364   \n",
       "323       0.088521  1.472774e-02         0.005207        0.007364   \n",
       "\n",
       "    param_colsample_bytree param_gamma param_learning_rate param_max_depth  \\\n",
       "0                      0.5           0                 0.1               3   \n",
       "1                      0.5           0                 0.1               3   \n",
       "2                      0.5           0                 0.1               3   \n",
       "3                      0.5           0                 0.1               3   \n",
       "4                      0.5           0                 0.1               3   \n",
       "..                     ...         ...                 ...             ...   \n",
       "319                    0.5           1                0.05               7   \n",
       "320                    0.5           1                0.05               7   \n",
       "321                    0.5           1                0.05               7   \n",
       "322                    0.5           1                0.05               7   \n",
       "323                    0.5           1                0.05               7   \n",
       "\n",
       "    param_reg_lambda param_scale_pos_weight param_subsample  \\\n",
       "0                  0                      1             0.8   \n",
       "1                  0                      3             0.8   \n",
       "2                  0                      5             0.8   \n",
       "3                  1                      1             0.8   \n",
       "4                  1                      3             0.8   \n",
       "..               ...                    ...             ...   \n",
       "319                1                      3             0.8   \n",
       "320                1                      5             0.8   \n",
       "321               10                      1             0.8   \n",
       "322               10                      3             0.8   \n",
       "323               10                      5             0.8   \n",
       "\n",
       "                                                params  split0_test_score  \\\n",
       "0    {'colsample_bytree': 0.5, 'gamma': 0, 'learnin...           0.998291   \n",
       "1    {'colsample_bytree': 0.5, 'gamma': 0, 'learnin...           0.998077   \n",
       "2    {'colsample_bytree': 0.5, 'gamma': 0, 'learnin...           0.997222   \n",
       "3    {'colsample_bytree': 0.5, 'gamma': 0, 'learnin...           0.997863   \n",
       "4    {'colsample_bytree': 0.5, 'gamma': 0, 'learnin...           0.998291   \n",
       "..                                                 ...                ...   \n",
       "319  {'colsample_bytree': 0.5, 'gamma': 1, 'learnin...           0.996795   \n",
       "320  {'colsample_bytree': 0.5, 'gamma': 1, 'learnin...           0.996795   \n",
       "321  {'colsample_bytree': 0.5, 'gamma': 1, 'learnin...           0.992308   \n",
       "322  {'colsample_bytree': 0.5, 'gamma': 1, 'learnin...           0.996581   \n",
       "323  {'colsample_bytree': 0.5, 'gamma': 1, 'learnin...           0.995726   \n",
       "\n",
       "     split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "0             0.977740           0.988552         0.988194        0.008394   \n",
       "1             0.973924           0.991308         0.987770        0.010173   \n",
       "2             0.976892           0.989824         0.987979        0.008402   \n",
       "3             0.976468           0.989612         0.987981        0.008810   \n",
       "4             0.979648           0.989188         0.989042        0.007611   \n",
       "..                 ...                ...              ...             ...   \n",
       "319           0.977104           0.988976         0.987625        0.008095   \n",
       "320           0.975620           0.989188         0.987201        0.008758   \n",
       "321           0.976256           0.985796         0.984787        0.006592   \n",
       "322           0.975832           0.989400         0.987271        0.008604   \n",
       "323           0.975832           0.990460         0.987340        0.008416   \n",
       "\n",
       "     rank_test_score  \n",
       "0                 38  \n",
       "1                 70  \n",
       "2                 57  \n",
       "3                 53  \n",
       "4                  2  \n",
       "..               ...  \n",
       "319               86  \n",
       "320              125  \n",
       "321              237  \n",
       "322              121  \n",
       "323              114  \n",
       "\n",
       "[324 rows x 18 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg_grid_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "27b7533e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9891818976883636"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg_grid_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b581cfad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.5,\n",
       " 'gamma': 0,\n",
       " 'learning_rate': 0.1,\n",
       " 'max_depth': 4,\n",
       " 'reg_lambda': 1,\n",
       " 'scale_pos_weight': 3,\n",
       " 'subsample': 0.8}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg_grid_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0f7badf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf4=xg_grid_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6381d836",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:54:48] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.5,\n",
       "              enable_categorical=False, gamma=0, gpu_id=-1,\n",
       "              importance_type=None, interaction_constraints='',\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=4,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=4, num_parallel_tree=1, predictor='auto',\n",
       "              random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=3,\n",
       "              subsample=0.8, tree_method='exact', validate_parameters=1,\n",
       "              verbosity=None)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf4.fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6ce1895d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9790209790209791"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf4.score(xtest,ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "4c9e44c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=clf4.predict(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7f15d67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report , accuracy_score, confusion_matrix, plot_roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "7e455db4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           B       0.99      0.98      0.98        89\n",
      "           M       0.96      0.98      0.97        54\n",
      "\n",
      "    accuracy                           0.98       143\n",
      "   macro avg       0.98      0.98      0.98       143\n",
      "weighted avg       0.98      0.98      0.98       143\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(ytest,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "da8560f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix = confusion_matrix(ytest,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "65f4695a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[87,  2],\n",
       "       [ 1, 53]], dtype=int64)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "daf59c17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.roc_curve.RocCurveDisplay at 0x2a77e69a7f0>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_roc_curve(clf4,xtest,ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b49c82",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning of XGBoost with Randomized Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c339954f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "93947ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"max_depth\": [3, 4, 5, 7],\n",
    "    \"learning_rate\": [0.1, 0.01, 0.05],\n",
    "    \"gamma\": [0, 0.25, 1],\n",
    "    \"reg_lambda\": [0, 1, 10],\n",
    "    \"scale_pos_weight\": [1, 3, 5],\n",
    "    \"subsample\": [0.8],\n",
    "    \"colsample_bytree\": [0.5],\n",
    "}              #subsample and colsample_bytree to recommended values to speed things up and prevent overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "59e47635",
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_ran_cv=RandomizedSearchCV(xg_clf, param_grid, n_jobs=-1, cv=3, scoring=\"roc_auc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "b2e6790f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:54:49] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3,\n",
       "                   estimator=XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                                           colsample_bylevel=1,\n",
       "                                           colsample_bynode=1,\n",
       "                                           colsample_bytree=1,\n",
       "                                           enable_categorical=False, gamma=0,\n",
       "                                           gpu_id=-1, importance_type=None,\n",
       "                                           interaction_constraints='',\n",
       "                                           learning_rate=0.300000012,\n",
       "                                           max_delta_step=0, max_depth=6,\n",
       "                                           min_child_weight=1, missing=nan,\n",
       "                                           monotone_constraints='()',\n",
       "                                           n_estimat...\n",
       "                                           predictor='auto', random_state=0,\n",
       "                                           reg_alpha=0, reg_lambda=1,\n",
       "                                           scale_pos_weight=1, subsample=1,\n",
       "                                           tree_method='exact',\n",
       "                                           validate_parameters=1,\n",
       "                                           verbosity=None),\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'colsample_bytree': [0.5],\n",
       "                                        'gamma': [0, 0.25, 1],\n",
       "                                        'learning_rate': [0.1, 0.01, 0.05],\n",
       "                                        'max_depth': [3, 4, 5, 7],\n",
       "                                        'reg_lambda': [0, 1, 10],\n",
       "                                        'scale_pos_weight': [1, 3, 5],\n",
       "                                        'subsample': [0.8]},\n",
       "                   scoring='roc_auc')"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg_ran_cv.fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "af9188a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9884051261515752"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg_ran_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "370c2349",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'subsample': 0.8,\n",
       " 'scale_pos_weight': 5,\n",
       " 'reg_lambda': 0,\n",
       " 'max_depth': 3,\n",
       " 'learning_rate': 0.1,\n",
       " 'gamma': 1,\n",
       " 'colsample_bytree': 0.5}"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg_ran_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d88dbb90",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf6=xg_ran_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "00c51898",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:54:49] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.5,\n",
       "              enable_categorical=False, gamma=1, gpu_id=-1,\n",
       "              importance_type=None, interaction_constraints='',\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=4, num_parallel_tree=1, predictor='auto',\n",
       "              random_state=0, reg_alpha=0, reg_lambda=0, scale_pos_weight=5,\n",
       "              subsample=0.8, tree_method='exact', validate_parameters=1,\n",
       "              verbosity=None)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf6.fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "7bc5d3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=clf6.predict(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "9fee09cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.965034965034965"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf6.score(xtest,ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "1ca3e0dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           B       0.99      0.96      0.97        89\n",
      "           M       0.93      0.98      0.95        54\n",
      "\n",
      "    accuracy                           0.97       143\n",
      "   macro avg       0.96      0.97      0.96       143\n",
      "weighted avg       0.97      0.97      0.97       143\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(ytest,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8070d37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
